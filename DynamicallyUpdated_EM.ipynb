{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate the data \n",
    "I'm aiming to generate 100000 datapoints from a Gaussian mixture model of k = 15 components. For simplicity, each datapoint is a scalar (1-dimension). \n",
    "To make it more realistic, I will random the weight of each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000 # Number of datapoints\n",
    "k = 15 # Number of components\n",
    "\n",
    "# Randomising the weights\n",
    "weights = np.random.uniform(low = 0.75, high = 1, size=(k, ))\n",
    "weights = weights / np.sum(weights) \n",
    "assert abs(np.sum(weights) - 1) < 0.0000001 # Ensuring a convex linear combination\n",
    "\n",
    "# Decide which component we will sample from\n",
    "mixture_index = np.random.choice(k, size = n, replace = True, p = weights)\n",
    "assert mixture_index.shape == (n, )\n",
    "\n",
    "# Decide the random mean and variance of all 100 components\n",
    "mean = np.random.uniform(low=-12.5, high=12.5, size=(k, ))\n",
    "variance = np.random.uniform(low=0.75, high=1.5, size=(k, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data using numpy for efficiency\n",
    "data = np.fromiter((np.random.normal(loc = mean[index], scale = np.sqrt([variance[index]])[0]) for index in mixture_index), float)\n",
    "assert data.shape == (n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: The traditional EM algorithm\n",
    "The algorithm includes finding the probability of each point belonging to each component, then tune the mean and variance of each component according the the calculated probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, define a way to calculate pdf \n",
    "# This function is actually not used due to its low efficiency. See function calculate_p_matrix below\n",
    "def pdf(x, input_mean, input_var):\n",
    "    return math.exp(-0.5 * ((x - input_mean) ** 2 ) / input_var) / (math.sqrt(2 * math.pi * input_var))\n",
    "\n",
    "# Test the function\n",
    "assert pdf(0, 0, 1) == 0.3989422804014327\n",
    "assert pdf(0.5, 0, 1) == 0.3520653267642995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy to calculate pdf\n",
    "# Note that this p matrix is not yet normalised\n",
    "def calculate_p_matrix(x, input_mean, input_var, input_weight):\n",
    "    # Duplicate data so dimensions work out\n",
    "    mean_matrix = np.tile(input_mean, (len(x), 1)).T\n",
    "    variance_matrix = np.tile(input_var, (len(x), 1)).T\n",
    "    weight_matrix = np.tile(input_weight, (len(x), 1)).T\n",
    "    \n",
    "    # PDF calculation\n",
    "    p_matrix = weight_matrix * np.exp(-0.5 * np.power(x - mean_matrix, 2) / variance_matrix) / (np.sqrt(2 * np.pi * variance_matrix))\n",
    "    \n",
    "    p_matrix = p_matrix.transpose(1, 0)\n",
    "    \n",
    "    return p_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new [0.03701252 0.04243266 0.03601337 ... 0.04932846 0.03027117 0.04737035]\n",
      "old [0.03701252 0.04243266 0.03601337 ... 0.04932846 0.03027117 0.04737035]\n"
     ]
    }
   ],
   "source": [
    "# Define a metric to evaluate our return from EM alg.\n",
    "# Hardcoded P_value to save time\n",
    "\n",
    "# Old implementation\n",
    "old_P_value = np.zeros((n,))\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        old_P_value[i] += weights[j] * pdf(data[i], mean[j], variance[j])\n",
    "\n",
    "\n",
    "# New implementation with numpy, more efficient\n",
    "P_value = np.sum(calculate_p_matrix(data, mean, variance, weights), axis = 1)\n",
    "   \n",
    "print(\"new\", P_value)\n",
    "print(\"old\", old_P_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KL divergence is an integral from -inf to +inf, in this case, I only use the n datapoints that we already generated.\n",
    "# The addition of - P + Q was inspired by scipy's implementation of KL divergence. Apparently, it prevents KL divergence from going negative\n",
    "def KL_div(pred_mean, pred_variance, pred_weights):\n",
    "    # Old implementation\n",
    "    \"\"\"KL_divergence = 0\n",
    "    for i in range(n):\n",
    "        Q_value = 0\n",
    "        for j in range(k):\n",
    "            Q_value += pred_weights[j] * pdf(data[i], pred_mean[j], pred_variance[j])\n",
    "            #P_value += weights[j] * pdf(data[i], mean[j], variance[j])\n",
    "        KL_divergence += P_value[i] * math.log(P_value[i]/Q_value, math.e) - P_value[i] + Q_value\"\"\"\n",
    "    \n",
    "    \n",
    "    # New implementation\n",
    "    Q_value = np.sum(calculate_p_matrix(data, pred_mean, pred_variance, pred_weights), axis = 1)\n",
    "    \n",
    "    KL_divergence = np.sum(P_value * np.log(P_value / Q_value) - P_value + Q_value)\n",
    "    \n",
    "    return KL_divergence\n",
    "    \n",
    "assert KL_div(mean, variance, weights) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is based on Dr. Martha White's notes for CMPUT367, page 107. \n",
    "\n",
    "\"\"\"scaling_factor_plot = [[] for j in range(k)]\n",
    "print(scaling_factor_plot)\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Starts with random means, variances and weights\n",
    "predicted_mean_traditional = np.random.uniform(low=-5, high=5, size=(k, ))\n",
    "predicted_variance_traditional = np.random.uniform(low=0.5, high=5, size=(k, ))\n",
    "predicted_weights_traditional = np.random.random(size=(k, ))\n",
    "predicted_weights_traditional = predicted_weights_traditional / np.sum(predicted_weights_traditional) #normalising\n",
    "\n",
    "def traditional_EM():\n",
    "\n",
    "    \n",
    "    global predicted_mean_traditional, predicted_variance_traditional, predicted_weights_traditional\n",
    "    divergence_plot = [] # Array for plotting later\n",
    "    counter = 0 # Count iteration for printing divergence\n",
    "    \n",
    "    KL_divergence = KL_div(predicted_mean_traditional, predicted_variance_traditional, predicted_weights_traditional)\n",
    "    print(\"kl div:\", KL_divergence)\n",
    "    prev_divergence = math.inf\n",
    "    \n",
    "    \n",
    "    \n",
    "    while prev_divergence - KL_divergence > 0.0001 and KL_divergence > 0:\n",
    "        \n",
    "        # This is the old implementation using python loops. I need to redo this part in numpy to optimise bc it takes too much time.\n",
    "        \"\"\"for i in range(n):\n",
    "            denominator_sum = 0\n",
    "            for j in range(k):\n",
    "                probability_matrix[i, j] = predicted_weights[j] * pdf(data[i], predicted_mean[j], predicted_variance[j])\n",
    "            \n",
    "            denominator_sum = np.sum(probability_matrix[i, :])\n",
    "            \n",
    "            probability_matrix[i, :] = probability_matrix[i, :] / denominator_sum\"\"\"\n",
    "        \n",
    "        probability_matrix = calculate_p_matrix(data, predicted_mean_traditional, predicted_variance_traditional, predicted_weights_traditional)\n",
    "        # Normalise\n",
    "        probability_matrix = probability_matrix / np.sum(probability_matrix, axis = 1, keepdims=True)\n",
    "        \n",
    "        \"\"\"for j in range(k):\n",
    "            normalised_p_matrix[:, j] = probability_matrix[:, j] / np.sum(probability_matrix[:, j])\n",
    "            scaling_factor_plot[j].append(np.sum(probability_matrix[:, j]))\"\"\"\n",
    "            \n",
    "        normalised_p_matrix = probability_matrix / np.sum(probability_matrix, axis = 0, keepdims=True)\n",
    "        \n",
    "        \n",
    "        # Maximisation step\n",
    "        predicted_weights_traditional = (1/n) * np.sum(probability_matrix, axis = 0)\n",
    "        \n",
    "        mean_matrix = (data * normalised_p_matrix.T).T\n",
    "        predicted_mean_traditional = np.sum(mean_matrix, axis = 0)\n",
    "\n",
    "        predicted_variance_traditional = np.sum(np.multiply(np.power(np.tile(data, (k, 1)).T - predicted_mean_traditional, 2), normalised_p_matrix), axis = 0)\n",
    "        \n",
    "        \n",
    "        diff = prev_divergence - KL_divergence\n",
    "        prev_divergence = KL_divergence\n",
    "        KL_divergence = KL_div(predicted_mean_traditional, predicted_variance_traditional, predicted_weights_traditional)\n",
    "        \n",
    "        if counter % 15 == 0:\n",
    "            print(\"kl div:\", KL_divergence, \" |  iter:\", counter, \" |  difference vs the prev iter:\", diff)\n",
    "            \n",
    "            \n",
    "        divergence_plot.append(KL_divergence)\n",
    "        counter += 1\n",
    "    return divergence_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl div: 5458.433301781226\n",
      "kl div: 361.60194451609357  |  iter: 0  |  difference vs the prev iter: inf\n",
      "kl div: 81.9472432476312  |  iter: 15  |  difference vs the prev iter: 1.7499893858746702\n",
      "kl div: 56.61206693776511  |  iter: 30  |  difference vs the prev iter: 1.8610506688882325\n",
      "kl div: 23.72212568012575  |  iter: 45  |  difference vs the prev iter: 2.365576111707849\n",
      "kl div: 6.148227446140358  |  iter: 60  |  difference vs the prev iter: 0.44718110497620245\n",
      "kl div: 3.1930106711112254  |  iter: 75  |  difference vs the prev iter: 0.09371032913486266\n",
      "kl div: 2.592033628899608  |  iter: 90  |  difference vs the prev iter: 0.021278891036708103\n",
      "kl div: 2.395762011723056  |  iter: 105  |  difference vs the prev iter: 0.009889862952941808\n",
      "kl div: 2.283216776508712  |  iter: 120  |  difference vs the prev iter: 0.006216080879122732\n",
      "kl div: 2.209975655639958  |  iter: 135  |  difference vs the prev iter: 0.004170299010805234\n",
      "kl div: 2.1555855592558504  |  iter: 150  |  difference vs the prev iter: 0.003414836667811727\n",
      "kl div: 2.104124916627836  |  iter: 165  |  difference vs the prev iter: 0.003509476559238056\n",
      "kl div: 2.0484774282351688  |  iter: 180  |  difference vs the prev iter: 0.0038438947967325277\n",
      "kl div: 1.988575040225684  |  iter: 195  |  difference vs the prev iter: 0.004069177898576193\n",
      "kl div: 1.926979228782873  |  iter: 210  |  difference vs the prev iter: 0.004108539950317791\n",
      "kl div: 1.8661278104383332  |  iter: 225  |  difference vs the prev iter: 0.004008651254014506\n",
      "kl div: 1.807488051063723  |  iter: 240  |  difference vs the prev iter: 0.0038376884219526453\n",
      "kl div: 1.7516426421507763  |  iter: 255  |  difference vs the prev iter: 0.0036461440520405564\n",
      "kl div: 1.6986399421266667  |  iter: 270  |  difference vs the prev iter: 0.00345990627058268\n",
      "kl div: 1.64832608627548  |  iter: 285  |  difference vs the prev iter: 0.0032851504699933365\n",
      "kl div: 1.6005690841729765  |  iter: 300  |  difference vs the prev iter: 0.0031164336957318906\n",
      "kl div: 1.5553595503495405  |  iter: 315  |  difference vs the prev iter: 0.0029447358050049832\n",
      "kl div: 1.5128045952680123  |  iter: 330  |  difference vs the prev iter: 0.0027637893083973797\n",
      "kl div: 1.473051540472798  |  iter: 345  |  difference vs the prev iter: 0.0025735410967056005\n",
      "kl div: 1.4361893332227758  |  iter: 360  |  difference vs the prev iter: 0.0023803396368864416\n",
      "kl div: 1.4021716331040244  |  iter: 375  |  difference vs the prev iter: 0.002194567627152866\n",
      "kl div: 1.370786424568064  |  iter: 390  |  difference vs the prev iter: 0.0020272755184547187\n",
      "kl div: 1.3416727917345392  |  iter: 405  |  difference vs the prev iter: 0.001887349001346017\n",
      "kl div: 1.314368549693324  |  iter: 420  |  difference vs the prev iter: 0.0017800155001874707\n",
      "kl div: 1.2883679697254  |  iter: 435  |  difference vs the prev iter: 0.0017066753560237569\n",
      "kl div: 1.2631737354004098  |  iter: 450  |  difference vs the prev iter: 0.0016655809165706525\n",
      "kl div: 1.2383353934668846  |  iter: 465  |  difference vs the prev iter: 0.001652820235230612\n",
      "kl div: 1.2134735115122637  |  iter: 480  |  difference vs the prev iter: 0.0016632107882468272\n",
      "kl div: 1.1882928989736858  |  iter: 495  |  difference vs the prev iter: 0.0016909047767033059\n",
      "kl div: 1.1625896867293999  |  iter: 510  |  difference vs the prev iter: 0.0017296722614541515\n",
      "kl div: 1.1362564695373565  |  iter: 525  |  difference vs the prev iter: 0.0017729439465086205\n",
      "kl div: 1.109287811430368  |  iter: 540  |  difference vs the prev iter: 0.00181376475267081\n",
      "kl div: 1.0817858931998436  |  iter: 555  |  difference vs the prev iter: 0.0018448307521101714\n",
      "kl div: 1.053963735140964  |  iter: 570  |  difference vs the prev iter: 0.0018587472906885782\n",
      "kl div: 1.0261421042193604  |  iter: 585  |  difference vs the prev iter: 0.001848558014144741\n",
      "kl div: 0.9987364313459154  |  iter: 600  |  difference vs the prev iter: 0.0018084889241256619\n",
      "kl div: 0.9722315919038202  |  iter: 615  |  difference vs the prev iter: 0.0017347825728032396\n",
      "kl div: 0.9471444433510424  |  iter: 630  |  difference vs the prev iter: 0.0016264848828277945\n",
      "kl div: 0.9239760216778427  |  iter: 645  |  difference vs the prev iter: 0.0014860514518169055\n",
      "kl div: 0.9031574919844347  |  iter: 660  |  difference vs the prev iter: 0.0013196131026771418\n",
      "kl div: 0.8849967763063453  |  iter: 675  |  difference vs the prev iter: 0.0011366951528881675\n",
      "kl div: 0.8696358144146868  |  iter: 690  |  difference vs the prev iter: 0.000949206350947307\n",
      "kl div: 0.8570297454316145  |  iter: 705  |  difference vs the prev iter: 0.0007696968765446011\n",
      "kl div: 0.8469563659844023  |  iter: 720  |  difference vs the prev iter: 0.0006092242161771511\n",
      "kl div: 0.8390561668301175  |  iter: 735  |  difference vs the prev iter: 0.0004754731235206977\n",
      "kl div: 0.8328930386204769  |  iter: 750  |  difference vs the prev iter: 0.00037178060225784293\n",
      "kl div: 0.8280190250245422  |  iter: 765  |  difference vs the prev iter: 0.0002973363370214477\n",
      "kl div: 0.8240272030363582  |  iter: 780  |  difference vs the prev iter: 0.00024830656581287247\n",
      "kl div: 0.8205837614959537  |  iter: 795  |  difference vs the prev iter: 0.00021931677830500096\n",
      "kl div: 0.8174388713957004  |  iter: 810  |  difference vs the prev iter: 0.00020476447622541638\n",
      "kl div: 0.8144217279829564  |  iter: 825  |  difference vs the prev iter: 0.00019968514017820738\n",
      "kl div: 0.8114269001042065  |  iter: 840  |  difference vs the prev iter: 0.00020015058117806017\n",
      "kl div: 0.8083979911461416  |  iter: 855  |  difference vs the prev iter: 0.00020332228325481427\n",
      "kl div: 0.8053123996315454  |  iter: 870  |  difference vs the prev iter: 0.00020731236628457328\n",
      "kl div: 0.8021689268327254  |  iter: 885  |  difference vs the prev iter: 0.00021097254845170443\n",
      "kl div: 0.798978603834578  |  iter: 900  |  difference vs the prev iter: 0.00021368372523955514\n",
      "kl div: 0.795758390410251  |  iter: 915  |  difference vs the prev iter: 0.00021517959040318058\n",
      "kl div: 0.792527134275807  |  iter: 930  |  difference vs the prev iter: 0.00021541318848861124\n",
      "kl div: 0.7893031683974562  |  iter: 945  |  difference vs the prev iter: 0.00021446299609495512\n",
      "kl div: 0.7861030226140655  |  iter: 960  |  difference vs the prev iter: 0.00021247058942719388\n",
      "kl div: 0.7829408522360533  |  iter: 975  |  difference vs the prev iter: 0.00020960149483939539\n",
      "kl div: 0.779828302143089  |  iter: 990  |  difference vs the prev iter: 0.00020602207288344943\n",
      "kl div: 0.7767746171646667  |  iter: 1005  |  difference vs the prev iter: 0.0002018869564358594\n",
      "kl div: 0.7737868771490124  |  iter: 1020  |  difference vs the prev iter: 0.0001973331503706266\n",
      "kl div: 0.7708702820420462  |  iter: 1035  |  difference vs the prev iter: 0.00019247812736455927\n",
      "kl div: 0.768028443493269  |  iter: 1050  |  difference vs the prev iter: 0.0001874201944362941\n",
      "kl div: 0.7652636594755946  |  iter: 1065  |  difference vs the prev iter: 0.0001822400241570099\n",
      "kl div: 0.7625771607261791  |  iter: 1080  |  difference vs the prev iter: 0.00017700269837606086\n",
      "kl div: 0.7599693251329065  |  iter: 1095  |  difference vs the prev iter: 0.00017175986927620013\n",
      "kl div: 0.7574398602551139  |  iter: 1110  |  difference vs the prev iter: 0.00016655184532987644\n",
      "kl div: 0.7549879563035744  |  iter: 1125  |  difference vs the prev iter: 0.00016140947122633698\n",
      "kl div: 0.7526124127741489  |  iter: 1140  |  difference vs the prev iter: 0.00015635579958173107\n",
      "kl div: 0.750311742222373  |  iter: 1155  |  difference vs the prev iter: 0.00015140751655695617\n",
      "kl div: 0.7480842544809791  |  iter: 1170  |  difference vs the prev iter: 0.00014657616851776467\n",
      "kl div: 0.7459281243768654  |  iter: 1185  |  difference vs the prev iter: 0.0001418691810222139\n",
      "kl div: 0.7438414456073368  |  iter: 1200  |  difference vs the prev iter: 0.00013729072101331674\n",
      "kl div: 0.7418222730917399  |  iter: 1215  |  difference vs the prev iter: 0.0001328424036310949\n",
      "kl div: 0.7398686557618191  |  iter: 1230  |  difference vs the prev iter: 0.0001285238877881678\n",
      "kl div: 0.7379786614654613  |  iter: 1245  |  difference vs the prev iter: 0.00012433335617956232\n",
      "kl div: 0.7361503953973969  |  iter: 1260  |  difference vs the prev iter: 0.00012026791718122709\n",
      "kl div: 0.7343820132418241  |  iter: 1275  |  difference vs the prev iter: 0.00011632392680460679\n",
      "kl div: 0.7326717300431266  |  iter: 1290  |  difference vs the prev iter: 0.00011249725111184272\n",
      "kl div: 0.7310178256400852  |  iter: 1305  |  difference vs the prev iter: 0.00010878346861642463\n",
      "kl div: 0.7294186473851182  |  iter: 1320  |  difference vs the prev iter: 0.00010517804407916831\n",
      "kl div: 0.727872610748625  |  iter: 1335  |  difference vs the prev iter: 0.00010167644749425886\n"
     ]
    }
   ],
   "source": [
    "# Will take abt 5 to 10 minutes to run and converge\n",
    "divergence_plot = traditional_EM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TARGET DISTRIBUTION ------\n",
      "component mean: -11.672613653432812 | variance: 1.0318433374469609 | weight: 0.05922185651796089\n",
      "component mean: -1.6074978744599928 | variance: 1.4333473867299162 | weight: 0.07063756819430572\n",
      "component mean: 4.094745312277848 | variance: 1.118858920609918 | weight: 0.061811751433560595\n",
      "component mean: 2.0572158547178674 | variance: 0.9587485734299261 | weight: 0.06393055931356285\n",
      "component mean: 5.63144232576137 | variance: 1.4184678949321632 | weight: 0.06587811082683495\n",
      "component mean: 4.091217942458851 | variance: 1.1522444150442825 | weight: 0.06951439624583526\n",
      "component mean: 11.223438473589585 | variance: 0.8535344460937175 | weight: 0.07267766848694315\n",
      "component mean: -3.812700078255112 | variance: 1.1586812443684433 | weight: 0.06103108899649268\n",
      "component mean: 7.370933412557804 | variance: 0.8590739652181271 | weight: 0.07226443611739235\n",
      "component mean: -4.854918987713738 | variance: 0.9630536117705006 | weight: 0.07158472816691576\n",
      "component mean: 5.248183204935533 | variance: 1.1963936252413494 | weight: 0.06463054296978654\n",
      "component mean: -10.965718209702032 | variance: 0.8555609658043344 | weight: 0.06282529358450628\n",
      "component mean: -0.7757519952718983 | variance: 0.8064832113266853 | weight: 0.06839975764864731\n",
      "component mean: -1.5849420222917612 | variance: 1.3038320161128822 | weight: 0.07331186728708637\n",
      "component mean: 10.261401355035058 | variance: 1.1548982524749443 | weight: 0.06228037421016924\n",
      "----- LEARNED DISTRIBUTION ------\n",
      "component mean: 4.614968731055825 | variance: 0.642473540722281 | weight: 0.07523892664905237\n",
      "component mean: 6.594853587055508 | variance: 2.1438111871766075 | weight: 0.1697323805628524\n",
      "component mean: -2.569126284165913 | variance: 1.6003723770859521 | weight: 0.0365813076266676\n",
      "component mean: -2.7886670057764777 | variance: 1.5282366211694909 | weight: 0.01776924353333551\n",
      "component mean: -4.868252289669841 | variance: 0.8860048567437382 | weight: 0.08306084976826117\n",
      "component mean: 10.918302371501078 | variance: 1.0024323470087217 | weight: 0.12329773852193951\n",
      "component mean: 0.9964763934663229 | variance: 4.896776359267162 | weight: 0.027489401306351045\n",
      "component mean: 4.545154467409141 | variance: 4.720864984153444 | weight: 0.004047279884487399\n",
      "component mean: -1.1814787847994008 | variance: 0.6062947070713004 | weight: 0.09211280399789665\n",
      "component mean: -2.8313525726084032 | variance: 1.5102080579573036 | weight: 0.07040741134366106\n",
      "component mean: -11.30106806494969 | variance: 1.059022080825318 | weight: 0.11979207103926413\n",
      "component mean: -0.26378271071181003 | variance: 0.3145850063054937 | weight: 0.02382312637544145\n",
      "component mean: 3.252321006597234 | variance: 0.7331218323297064 | weight: 0.022094574089584387\n",
      "component mean: 3.814826433843832 | variance: 4.682479469384752 | weight: 0.02301464863289534\n",
      "component mean: 2.928858278988681 | variance: 2.9437825110528104 | weight: 0.1115382366682844\n"
     ]
    }
   ],
   "source": [
    "print(\"----- TARGET DISTRIBUTION ------\")\n",
    "for i in range(k):\n",
    "    print(\"component mean:\", mean[i], \"| variance:\", variance[i], \"| weight:\", weights[i])\n",
    "\n",
    "print(\"----- LEARNED DISTRIBUTION ------\")\n",
    "for i in range(k):\n",
    "    print(\"component mean:\", predicted_mean_traditional[i], \"| variance:\", predicted_variance_traditional[i], \"| weight:\", predicted_weights_traditional[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(divergence_plot[15:]))], divergence_plot[15:])\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"kl_divergence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbFElEQVR4nO3df5RfdX3n8eerQYO/ihrGHyRAosTdE9qKNYJnq1ZFa6i2wTYo6LF0F43umu2eo9bGU5fSrLbiaYttoSoWlGIVKF11XGNxlW1dLcUMij+Ch+0QqUlECSFFUQNE3vvH94Z++ebOZBLmznd+PB/nzMm99/O5977vTOb7ns/nc+/npqqQJGnQTw07AEnS7GSCkCS1MkFIklqZICRJrUwQkqRWJghJUisThDRFST6U5B1TrLs8SSU5oln/dJKzpymO5ya5uW/91iQvmo5jN8fbmuT503U8zV1HDDsALUxJbgVeW1WfHXYsM6GqTptKvSQFrKyq8UmO9X+BfzcdcSX5ELCjqt7ed/wTp+PYmvtsQWjeSrJo2DFMt/0tEmkmmCA0qyT5qSQbk9ySZHeSq5I8vq/8b5J8N8ldST6f5MS+sg8leW+SzUl+CLyg6X55S5KvNftcmeTIvn1eluTGJP+a5B+T/Fxf2TOSfDnJD5JcCTywX0vci5L8UZI7kmwDXjpQ/vdJXtssn5DkH5p47miOTZLPN9W/muTuJK9M8vwkO5L8TpLvAh/cv20ghGcluSnJniQf3H+NSX4zyRcGYqkmhvXAq4G3Nuf7ZFP+QJdVksVJ3pPkO83Xe5Isbsr2x/bmJLcnuS3Jf5zs56u5xQSh2ea/AqcDvwgcA+wBLuor/zSwEngC8GXgrwf2fxXwTuAxwP4PxlcAa4AVwM8Bvwm9BABcCrweWAK8HxhtPhQfDnwcuBx4PPA3wK9PEvfrgJcBzwBWA+smqfs/gM8AjwOWAX8OUFXPa8qfXlWPrqorm/UnNTEcD6yf4JivBl4CPBV4GvD2Ceo9oKoupvf9e3dzvl9pqfa7wLOBk4CnAycPHPtJwFHAUuAc4KIkjzvYuTU3mCA027wB+N2q2lFV9wDnAev2d61U1aVV9YO+sqcnOapv/09U1Rer6v6q2tts+7Oq+k5V3Ql8kt6HHfQ+bN9fVddX1U+q6jLgHnofiM8GHga8p6ruq6qrgS2TxP2Kpu725jx/OEnd++h92B9TVXur6guT1AW4H/i9qrqnqn48QZ0L+879TuCsgxxzql4NbKqq26tqF/D7wGv6yu9ryu+rqs3A3UzT+IiGzwSh2eZ44GNNl8+/At8EfgI8senGeVfT/fR94NZmn6P79t/ecszv9i3/CHh037nevP9czfmOpddyOQbYWQ+ezfJfJon7mIFzT1b3rUCALzV3DP2nSeoC7OpLdhMZPPcxB6k/Vcfw4GsZPPbuqtrXt97//dUcZ4LQbLMdOK2qHtv3dWRV7aTXfbQWeBG9bo3lzT7p2/9QpifeDrxz4FyPrKqPArcBS5P0H/u4SY51G73kctC6VfXdqnpdVR1Dr3vrL5KcMMmxp3JNg+f+TrP8Q+CR+wuSPOkQj/0deom07dia50wQGqaHJTmy7+sI4H3AO5McD5BkJMnapv5j6HUB7ab3ofcHD/H8HwDekOSU9DwqyUuTPAa4DtgH/FaShyX5NXr97xO5qqm7rOmD3zhRxSRnJFnWrO6h9yF9f7P+PeAph3Etb2zO/Xh64wb7xy++CpyY5KRm4Pq8gf0Odr6PAm9vfg5HA+cCHz6M+DQHmSA0TJuBH/d9nQf8KTAKfCbJD4B/Ak5p6v8VvS6OncBNTdlhq6oxeoPLF9L7oB6nGcCuqnuBX2vW7wReCfzPSQ73AeAaeh/IXz5I3WcB1ye5m961/req2taUnQdc1nR5veIQLucj9Aa+twG3AO9oruP/AZuAzwL/zL8N3O93CbCqOd/HW477DmAM+Brw9ebapvSwoOa++MIgSVIbWxCSpFYmCElSKxOEJKmVCUKS1GreTPx19NFH1/Lly4cdhiTNKTfccMMdVTXSVjZvEsTy5csZGxsbdhiSNKckmfCpf7uYJEmtTBCSpFYmCElSq04TRJI1SW5OMp7kgLlpmnn3r2zKr0+yvNn+sCSXJfl6km8meVuXcUqSDtRZgkjvdY8XAacBq4CzkqwaqHYOsKeqTgAuAM5vtp8BLK6qnwWeCbx+f/KQJM2MLlsQJwPjVbWtmfjsCnpTNfdbC1zWLF8NnNpMr1zAo5rZPR8B3At8v8NYJUkDukwQS3nwS0x2NNta6zQvHbmL3qsfr6Y3j/1twLeBP2relPUgSdYnGUsytmvXrum/AklawGbrIPXJ9N4idgy99wi/OckBc9ZX1cVVtbqqVo+MtD7nIUk6TF0miJ08+C1Xy5ptrXWa7qSj6L0M5lXA3zXvub0d+CK9F8FLkmZIl09SbwFWJllBLxGcSe+Dv98ocDa9t3etA66tqkrybeCFwOVJHkXvBfLv6TBWSVOwfOOnHrR+67teOqRINBM6a0E0Ywob6L1l65vAVVW1NcmmJL/aVLsEWJJkHHgT//aaxouARyfZSi/RfLCqvtZVrJKkA3U6F1NVbab3Wsn+bef2Le+ld0vr4H53t22XNPMGWw1aOGbrILUkachMEJKkViYISVIrE4QkqZUJQpLUygQhSWplgpAktTJBSJJamSAkSa06fZJaWiico0jzkS0ISVIrWxCSHsS5l7SfLQhJUitbEJIOm2Mv85sJQjoMdsNoIbCLSZLUygQhSWrVaYJIsibJzUnGk2xsKV+c5Mqm/Poky5vtr05yY9/X/UlO6jJWSdKDdZYgkiyi927p04BVwFlJVg1UOwfYU1UnABcA5wNU1V9X1UlVdRLwGuBbVXVjV7FKkg7UZQviZGC8qrZV1b3AFcDagTprgcua5auBU5NkoM5Zzb6SpBnUZYJYCmzvW9/RbGutU1X7gLuAJQN1Xgl8tO0ESdYnGUsytmvXrmkJWpLUM6sHqZOcAvyoqr7RVl5VF1fV6qpaPTIyMsPRSdL81mWC2Akc27e+rNnWWifJEcBRwO6+8jOZoPUgSepWlwliC7AyyYokD6f3YT86UGcUOLtZXgdcW1UFkOSngFfg+IMkDUVnT1JX1b4kG4BrgEXApVW1NckmYKyqRoFLgMuTjAN30ksi+z0P2F5V27qKUZoqn5yeGqfemF86nWqjqjYDmwe2ndu3vBc4Y4J9/x54dpfxSZImNqsHqSVJw+NkfVIH7GrRfGALQpLUygQhSWplgpAktTJBSJJamSAkSa1MEJKkVt7mKi1wPiWuidiCkCS1MkFIklqZICRJrUwQkqRWJghJUisThCSplQlCktTK5yAkdcZpz+e2TlsQSdYkuTnJeJKNLeWLk1zZlF+fZHlf2c8luS7J1iRfT3Jkl7FKkh6sswSRZBFwEXAasAo4K8mqgWrnAHuq6gTgAuD8Zt8jgA8Db6iqE4HnA/d1Fask6UBdtiBOBsaraltV3QtcAawdqLMWuKxZvho4NUmAXwK+VlVfBaiq3VX1kw5jlSQN6DJBLAW2963vaLa11qmqfcBdwBLgaUAluSbJl5O8te0ESdYnGUsytmvXrmm/AElayGbrXUxHAM8BXt38+/Ikpw5WqqqLq2p1Va0eGRmZ6RglaV7r8i6mncCxfevLmm1tdXY04w5HAbvptTY+X1V3ACTZDPw88LkO45Ue4AynUrctiC3AyiQrkjwcOBMYHagzCpzdLK8Drq2qAq4BfjbJI5vE8YvATR3GKkka0FkLoqr2JdlA78N+EXBpVW1NsgkYq6pR4BLg8iTjwJ30kghVtSfJn9BLMgVsrir/pJOkGdTpg3JVtRnYPLDt3L7lvcAZE+z7YXq3ukqShmC2DlJLkobMqTakBcYBeE2VLQhJUisThCSplV1MkmaMs7vOLbYgJEmtTBCSpFYmCElSK8cgpBlg37vmIlsQkqRWJghJUisThCSplQlCktTKBCFJauVdTBJOYDcs3t01u5kgJGkKFmIys4tJktSq0wSRZE2Sm5OMJ9nYUr44yZVN+fVJljfblyf5cZIbm6/3dRmnJOlAnXUxJVkEXAS8GNgBbEkyWlU39VU7B9hTVSckORM4H3hlU3ZLVZ3UVXySpMl1OQZxMjBeVdsAklwBrAX6E8Ra4Lxm+WrgwiTpMCYJcFBamoouu5iWAtv71nc021rrVNU+4C5gSVO2IslXkvxDkud2GKckqcVsvYvpNuC4qtqd5JnAx5OcWFXf76+UZD2wHuC4444bQpiSNH912YLYCRzbt76s2dZaJ8kRwFHA7qq6p6p2A1TVDcAtwNMGT1BVF1fV6qpaPTIy0sElSNLC1WULYguwMskKeongTOBVA3VGgbOB64B1wLVVVUlGgDur6idJngKsBLZ1GKs0bzneosPVWYKoqn1JNgDXAIuAS6tqa5JNwFhVjQKXAJcnGQfupJdEAJ4HbEpyH3A/8IaqurOrWCVJB+p0DKKqNgObB7ad27e8FzijZb+/Bf62y9gkSZPzSWpJUisThCSp1Wy9zVU6ZAtxMjWpSyYIzVnenSN1ywShecsWhR4K/wAxQWgB8RdeOjQOUkuSWtmCmAP6//K1m0Tzmd2Cs4stCElSK1sQmjMcQ9BsshBaOyYIaZ4xkWq62MUkSWo1pRZEkicAvwAcA/wY+Aa9GVnv7zA2SdIQTZogkrwA2Ag8HvgKcDtwJHA68NQkVwN/PPimN3VnIfR7SpodDtaC+GXgdVX17cGC5g1wLwNejFNzS9K8M2mCqKrfnqRsH/Dx6Q5IkjQ7THUM4nJgQ1Xd1awvBy6pqlM7jG3B8i4USbPBVG9z/QJwfZI3AUuB3wbe3FlUkoRjbsM2pdtcq+r9wGuBTwCbgOdV1ScPtl+SNUluTjKeZGNL+eIkVzbl1zctk/7y45LcneQtU7oaSdK0mVKCSPIa4FLgN4APAZuTPP0g+ywCLgJOA1YBZyVZNVDtHGBPVZ0AXACcP1D+J8CnpxKjJGl6TbWL6deB51TV7cBHk3yMXqJ4xiT7nAyMV9U2gCRXAGuBm/rqrAXOa5avBi5MkqqqJKcD3wJ+OMUYJemwOfZ3oKl2MZ3eJIf9618CTjnIbkuB7X3rO5ptrXWau6LuApYkeTTwO8DvT3aCJOuTjCUZ27Vr11QuRZI0RZMmiCRvT/L4trKqujfJC5O8rIO4zgMuqKq7J6tUVRdX1eqqWj0yMtJBGJK0cB2si+nrwCeT7AW+DOyi9yT1SuAk4LPAH0yw707g2L71Zc22tjo7mgfvjgJ202udrEvybuCxwP1J9lbVhVO7LEnSQ3WwBLGuqn4hyVvpTbPxZOD7wIeB9VX140n23QKsTLKCXiI4E3jVQJ1R4GzgOmAdcG1VFfDc/RWSnAfcbXKQpJl1sATxzCTHAK8GXjBQ9gh6E/e1qqp9STYA1wCLgEuramuSTfQm+hsFLgEuTzIO3EkviUiSZoGDJYj3AZ8DngKM9W0PUM32CVXVZmDzwLZz+5b3Amcc5BjnHSRGac7xATDNBQebi+nPgD9L8t6q+s8zFJMEeNuhNGxTvc3V5CBJC4xvlJMktTJBSJJamSAkSa2mOheTZinvhpHUFROENMd5t5e6YheTJKmVCUKS1MoEIUlq5RiEJE2D+XjDiC0ISVIrWxCzgHehSJqNTBCS5oz52I0zm9nFJElqZYKQJLWyi0maYxyz0kzptAWRZE2Sm5OMJ9nYUr44yZVN+fVJljfbT05yY/P11SQv7zJOSdKBOksQSRYBFwGnAauAs5KsGqh2DrCnqk4ALgDOb7Z/A1hdVScBa4D3J7G1I0kzqMsWxMnAeFVtq6p7gSuAtQN11gKXNctXA6cmSVX9qKr2NduPpPf+a0nSDOryr/KlwPa+9R3AKRPVqap9Se4ClgB3JDkFuBQ4HnhNX8J4QJL1wHqA4447btovQNL85VjOwc3au5iq6vqqOhF4FvC2JEe21Lm4qlZX1eqRkZGZD1KS5rEuE8RO4Ni+9WXNttY6zRjDUcDu/gpV9U3gbuBnOotUknSALruYtgArk6yglwjOBF41UGcUOBu4DlgHXFtV1eyzvel2Oh7498CtHcYqDVV/d4dPB2u26CxBNB/uG4BrgEXApVW1NckmYKyqRoFLgMuTjAN30ksiAM8BNia5D7gf+C9VdUdXsUqSDtTpraNVtRnYPLDt3L7lvcAZLftdDlzeZWySpMnN2kFqSdJwmSAkSa18OnmecTpkSdPFBKFZwweXdKi8+6tbJghpljNxalgcg5AktbIFIc0ythg0W9iCkCS1MkFIklrZxSRJHZgPd1jZgpAktTJBSJJa2cUkaUHw7rBDZwtCktTKFsQQ+JeMNP2ch2z62YKQJLWyBSFpXrKl/tB12oJIsibJzUnGk2xsKV+c5Mqm/Poky5vtL05yQ5KvN/++sMs4JUkH6ixBJFkEXAScBqwCzkqyaqDaOcCeqjoBuAA4v9l+B/ArVfWzwNn4+lFJmnFdtiBOBsaraltV3QtcAawdqLMWuKxZvho4NUmq6itV9Z1m+1bgEUkWdxirJGlAlwliKbC9b31Hs621TlXtA+4ClgzU+XXgy1V1z+AJkqxPMpZkbNeuXdMWuCRplt/FlOREet1Or28rr6qLq2p1Va0eGRmZ2eAkaZ7rMkHsBI7tW1/WbGutk+QI4Chgd7O+DPgY8BtVdUuHcUqSWnSZILYAK5OsSPJw4ExgdKDOKL1BaIB1wLVVVUkeC3wK2FhVX+wwRknSBDpLEM2YwgbgGuCbwFVVtTXJpiS/2lS7BFiSZBx4E7D/VtgNwAnAuUlubL6e0FWskqQDdfqgXFVtBjYPbDu3b3kvcEbLfu8A3tFlbBo+H2SSZrdZPUgtSRoep9qY55zATNLhsgUhSWplgpAktTJBSJJamSAkSa1MEJKkViYISVIrE4QkqZUJQpLUygflJKljc/WBVRPEDHDOIUlzkV1MkqRWJghJUisThCSplQlCktTKBCFJatVpgkiyJsnNScaTbGwpX5zkyqb8+iTLm+1LkvyfJHcnubDLGCVJ7TpLEEkWARcBpwGrgLOSrBqodg6wp6pOAC4Azm+27wX+O/CWruKTJE2uyxbEycB4VW2rqnuBK4C1A3XWApc1y1cDpyZJVf2wqr5AL1FIkoagywfllgLb+9Z3AKdMVKeq9iW5C1gC3NFhXBoSHxiU5pY5PUidZH2SsSRju3btGnY4kjSvdJkgdgLH9q0va7a11klyBHAUsHuqJ6iqi6tqdVWtHhkZeYjhSpL6ddnFtAVYmWQFvURwJvCqgTqjwNnAdcA64Nqqqg5jWvDm6qRhkmZeZwmiGVPYAFwDLAIuraqtSTYBY1U1ClwCXJ5kHLiTXhIBIMmtwE8DD09yOvBLVXVTV/FKkh6s09lcq2ozsHlg27l9y3uBMybYd3mXsUmSJjenB6klSd3xfRCSNMPmyligLQhJUitbEB3wgTBJ84EtCElSKxOEJKmVCUKS1MoxiAVurtxNIWnm2YKQJLWyBaHOeDeXNLfZgpAktTJBSJJa2cUkSUM2W28WMUFMA/vaJc1HdjFJklqZICRJrexi0oM8lL5Qu9qk+cUEcRj8IJS0EHSaIJKsAf6U3jup/7Kq3jVQvhj4K+CZwG7glVV1a1P2NuAc4CfAb1XVNV3GKkmzxWy5q6mzBJFkEXAR8GJgB7AlyWhV3dRX7RxgT1WdkORM4HzglUlWAWcCJwLHAJ9N8rSq+klX8ardwf6j2pqS5q8uWxAnA+NVtQ0gyRXAWqA/QawFzmuWrwYuTJJm+xVVdQ/wrSTjzfGu6zDeB/ihNzG/N9LMO9jvXVctjC4TxFJge9/6DuCUiepU1b4kdwFLmu3/NLDv0sETJFkPrG9W705y8/SEDsDRwB3TeLxhmi/XMl+uA+bPtcyX64A5fC05/4BNh3Itx09UMKcHqavqYuDiLo6dZKyqVndx7Jk2X65lvlwHzJ9rmS/XAV5Lmy6fg9gJHNu3vqzZ1lonyRHAUfQGq6eyrySpQ10miC3AyiQrkjyc3qDz6ECdUeDsZnkdcG1VVbP9zCSLk6wAVgJf6jBWSdKAzrqYmjGFDcA19G5zvbSqtibZBIxV1ShwCXB5Mwh9J70kQlPvKnoD2vuANw7hDqZOuq6GZL5cy3y5Dpg/1zJfrgO8lgOk9we7JEkP5lxMkqRWJghJUisTxIAkZyTZmuT+JKv7ti9P8uMkNzZf7xtmnAcz0XU0ZW9LMp7k5iQvGVaMhyPJeUl29v0cfnnYMR2KJGua7/t4ko3DjuehSHJrkq83P4exYcdzKJJcmuT2JN/o2/b4JP87yT83/z5umDFOxQTXMW2/IyaIA30D+DXg8y1lt1TVSc3XG2Y4rkPVeh0D05isAf6imRZlLrmg7+ewedjBTFXf9DOnAauAs5qfx1z2gubnMNeeH/gQvf///TYCn6uqlcDnmvXZ7kMceB0wTb8jJogBVfXNqprOJ7KHYpLreGAak6r6FrB/GhN174HpZ6rqXmD/9DOaYVX1eXp3TvZbC1zWLF8GnD6TMR2OCa5j2pggDs2KJF9J8g9JnjvsYA5T2xQoB0xjMsttSPK1pnk967sB+syH732/Aj6T5IZm2pu57olVdVuz/F3gicMM5iGalt+RBZkgknw2yTdavib7a+424LiqegbwJuAjSX56ZiJud5jXMesd5LreCzwVOInez+SPhxnrAvecqvp5el1mb0zyvGEHNF2aB3bn6jMA0/Y7MqfnYjpcVfWiw9jnHuCeZvmGJLcATwOGNjh3ONfBHJjGZKrXleQDwP/qOJzpNOu/94eiqnY2/96e5GP0utDaxu7miu8leXJV3ZbkycDtww7ocFTV9/YvP9TfkQXZgjgcSUb2D+YmeQq96T+2DTeqwzKnpzFpfnH3ezm9wfi5YirTz8wJSR6V5DH7l4FfYm79LNr0T/1zNvCJIcZy2Kbzd2RBtiAmk+TlwJ8DI8CnktxYVS8BngdsSnIfcD/whqrqbHDooZroOmbJNCYPxbuTnESv+X8r8PqhRnMIJpp+ZshhHa4nAh9LAr3PkY9U1d8NN6SpS/JR4PnA0Ul2AL8HvAu4Ksk5wL8ArxhehFMzwXU8f7p+R5xqQ5LUyi4mSVIrE4QkqZUJQpLUygQhSWplgpAktTJBSJJamSAkSa1MEFJHkjyrmTDtyObJ461JfmbYcUlT5YNyUoeSvAM4EngEsKOq/nDIIUlTZoKQOtTMubQF2Av8hzk2rYkWOLuYpG4tAR4NPIZeS0KaM2xBSB1KMkrvzXErgCdX1YYhhyRNmbO5Sh1J8hvAfVX1kWaq+H9M8sKqunbYsUlTYQtCktTKMQhJUisThCSplQlCktTKBCFJamWCkCS1MkFIklqZICRJrf4/QNLBWDwcQyoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learned_mixture_index = np.random.choice(k, size = n, replace = True, p = predicted_weights_traditional)\n",
    "learned_data = np.fromiter((np.random.normal(loc = predicted_mean_traditional[index], scale = np.sqrt([predicted_variance_traditional[index]])[0]) for index in learned_mixture_index), float)\n",
    "assert data.shape == (n, )\n",
    "\n",
    "plt.hist(learned_data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Learned distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Actual distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic-update EM\n",
    "\n",
    "The traditional EM algorithm needs all the datapoint before making any changes to the weights, means and variances. From the idea of reinforcement learning, what if we update every time we see a datapoint (or a batch of datapoints)? In RL, dynamic programming value update will speed up the covergence rate significantly, and is proven to be an unbiased estimator of the actual value function. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2a. Constant stepsize \n",
    "Currently, it is not converging. I have not figured out why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl div: 7133.423675537747\n",
      "kl div: 19014.269964932835  |  iter: 0  |  difference vs the prev iter: inf\n",
      "kl div: 5365.6432006168225  |  iter: 15  |  difference vs the prev iter: 334.10354517076576\n",
      "kl div: 2468.742007157912  |  iter: 30  |  difference vs the prev iter: 124.67371247518577\n",
      "kl div: 1183.9277537161295  |  iter: 45  |  difference vs the prev iter: 63.644975710747985\n",
      "kl div: 524.9927187302486  |  iter: 60  |  difference vs the prev iter: 33.133490988560425\n",
      "kl div: 176.5709547203627  |  iter: 75  |  difference vs the prev iter: 16.95742467008614\n",
      "kl div: 25.708324846439254  |  iter: 90  |  difference vs the prev iter: 5.945340403249794\n",
      "kl div: 3.38153040706313  |  iter: 105  |  difference vs the prev iter: 0.030334593352160155\n",
      "kl div: 3.011065622347325  |  iter: 120  |  difference vs the prev iter: 0.020887958939204587\n",
      "kl div: 2.763656771568895  |  iter: 135  |  difference vs the prev iter: 0.014137593021811057\n",
      "kl div: 2.5961763756765412  |  iter: 150  |  difference vs the prev iter: 0.00958591008598697\n",
      "kl div: 2.4640377588504534  |  iter: 165  |  difference vs the prev iter: 0.009023739222113303\n",
      "kl div: 2.3375281736868287  |  iter: 180  |  difference vs the prev iter: 0.008318841085828144\n",
      "kl div: 2.203669216581221  |  iter: 195  |  difference vs the prev iter: 0.009157045840454625\n",
      "kl div: 2.0624991700384547  |  iter: 210  |  difference vs the prev iter: 0.008963172814282494\n",
      "kl div: 1.9170539921269953  |  iter: 225  |  difference vs the prev iter: 0.009711956975500424\n",
      "kl div: 1.7791870171677704  |  iter: 240  |  difference vs the prev iter: 0.008647309391399904\n",
      "kl div: 1.6617055448819662  |  iter: 255  |  difference vs the prev iter: 0.007657249718388215\n",
      "kl div: 1.567946507399994  |  iter: 270  |  difference vs the prev iter: 0.005724970374450633\n",
      "kl div: 1.494410956631569  |  iter: 285  |  difference vs the prev iter: 0.0042894418500336595\n",
      "kl div: 1.44088741468624  |  iter: 300  |  difference vs the prev iter: 0.0032024743299809977\n",
      "kl div: 1.403876144086616  |  iter: 315  |  difference vs the prev iter: 0.001970797122992307\n",
      "kl div: 1.3735007144916738  |  iter: 330  |  difference vs the prev iter: 0.002013333162489195\n",
      "kl div: 1.3474343778376314  |  iter: 345  |  difference vs the prev iter: 0.0008461098263004008\n",
      "kl div: 1.320842864726895  |  iter: 360  |  difference vs the prev iter: 0.001313753946609486\n",
      "kl div: 1.2973566793884992  |  iter: 375  |  difference vs the prev iter: 0.0017329018015539432\n",
      "kl div: 1.2741002554628382  |  iter: 390  |  difference vs the prev iter: 0.0012038765456421352\n",
      "kl div: 1.250418494885632  |  iter: 405  |  difference vs the prev iter: 0.0009883726804620352\n",
      "kl div: 1.2248646636855247  |  iter: 420  |  difference vs the prev iter: 0.0015697916605901252\n",
      "kl div: 1.2017469678235941  |  iter: 435  |  difference vs the prev iter: 0.0015321617020978007\n",
      "kl div: 1.1771087223856176  |  iter: 450  |  difference vs the prev iter: 0.00144878892314515\n",
      "kl div: 1.1550740825710437  |  iter: 465  |  difference vs the prev iter: 0.0012463481268809584\n",
      "kl div: 1.1374592525227705  |  iter: 480  |  difference vs the prev iter: 0.0010419368575327326\n",
      "kl div: 1.1226176145277476  |  iter: 495  |  difference vs the prev iter: 0.0007710352799850106\n",
      "kl div: 1.1136870595246107  |  iter: 510  |  difference vs the prev iter: 0.0002910705352199283\n",
      "kl div: 1.1075349768684675  |  iter: 525  |  difference vs the prev iter: 0.00020172028269138664\n",
      "kl div: 1.1045415413069324  |  iter: 540  |  difference vs the prev iter: 0.00010686687361305403\n",
      "kl div: 1.0994742988254995  |  iter: 555  |  difference vs the prev iter: -2.8801972024261602e-05\n",
      "kl div: 1.0953663395030544  |  iter: 570  |  difference vs the prev iter: -1.4089516643389643e-05\n",
      "kl div: 1.0937453579023302  |  iter: 585  |  difference vs the prev iter: -0.00031933531618788535\n",
      "kl div: 1.097052748827928  |  iter: 600  |  difference vs the prev iter: 0.00025884084995864143\n",
      "kl div: 1.0945556767540388  |  iter: 615  |  difference vs the prev iter: 8.31786990005412e-05\n",
      "kl div: 1.0927649997423088  |  iter: 630  |  difference vs the prev iter: 0.0008083467528201549\n",
      "kl div: 1.0874493731349524  |  iter: 645  |  difference vs the prev iter: 0.0013354596897414694\n",
      "kl div: 1.0818472900516276  |  iter: 660  |  difference vs the prev iter: 0.00010173812520597458\n",
      "kl div: 1.0801339570640187  |  iter: 675  |  difference vs the prev iter: 0.00027682020973274213\n",
      "kl div: 1.07867356113699  |  iter: 690  |  difference vs the prev iter: 0.0003745806239170424\n",
      "kl div: 1.0761122318554979  |  iter: 705  |  difference vs the prev iter: 0.00014230894327216248\n",
      "kl div: 1.074950388839005  |  iter: 720  |  difference vs the prev iter: 0.0003630932776939044\n",
      "kl div: 1.0743225260410647  |  iter: 735  |  difference vs the prev iter: -0.0004797382563923591\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tutha\\Desktop\\Personal Project\\DynamicallyUpdated-Expectation-Maximization-Algorithm\\DynamicallyUpdated_EM.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 60>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=56'>57</a>\u001b[0m         counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m divergence_plot\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m divergence_plot \u001b[39m=\u001b[39m dynamicEM()\n",
      "\u001b[1;32mc:\\Users\\tutha\\Desktop\\Personal Project\\DynamicallyUpdated-Expectation-Maximization-Algorithm\\DynamicallyUpdated_EM.ipynb Cell 19\u001b[0m in \u001b[0;36mdynamicEM\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m\"\"\"for i in range(n):\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m    denominator_sum = 0\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m    for j in range(k):\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39m    probability_matrix[i, :] = probability_matrix[i, :] / denominator_sum\"\"\"\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m index \u001b[39m=\u001b[39m counter \u001b[39m%\u001b[39m \u001b[39m1000\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m probability_matrix \u001b[39m=\u001b[39m calculate_p_matrix(data[index:(index \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m) \u001b[39m*\u001b[39;49m \u001b[39m1000\u001b[39;49m], predicted_mean_dynamic, predicted_variance_dynamic, predicted_weights_dynamic)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m \u001b[39m# Normalise\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m probability_matrix \u001b[39m=\u001b[39m probability_matrix \u001b[39m/\u001b[39m np\u001b[39m.\u001b[39msum(probability_matrix, axis \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m, keepdims\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\tutha\\Desktop\\Personal Project\\DynamicallyUpdated-Expectation-Maximization-Algorithm\\DynamicallyUpdated_EM.ipynb Cell 19\u001b[0m in \u001b[0;36mcalculate_p_matrix\u001b[1;34m(x, input_mean, input_var, input_weight)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m weight_matrix \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mtile(input_weight, (\u001b[39mlen\u001b[39m(x), \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mT\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# PDF calculation\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m p_matrix \u001b[39m=\u001b[39m weight_matrix \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mexp(\u001b[39m-\u001b[39m\u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39;49mpower(x \u001b[39m-\u001b[39;49m mean_matrix, \u001b[39m2\u001b[39;49m) \u001b[39m/\u001b[39m variance_matrix) \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39msqrt(\u001b[39m2\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39mpi \u001b[39m*\u001b[39m variance_matrix))\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m p_matrix \u001b[39m=\u001b[39m p_matrix\u001b[39m.\u001b[39mtranspose(\u001b[39m1\u001b[39m, \u001b[39m0\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/tutha/Desktop/Personal%20Project/DynamicallyUpdated-Expectation-Maximization-Algorithm/DynamicallyUpdated_EM.ipynb#X24sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m p_matrix\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predicted_mean_dynamic = np.random.uniform(low=-5, high=5, size=(k, ))\n",
    "predicted_variance_dynamic = np.random.uniform(low=0.5, high=5, size=(k, ))\n",
    "predicted_weights_dynamic = np.random.random(size=(k, ))\n",
    "predicted_weights_dynamic = predicted_weights_dynamic / np.sum(predicted_weights_dynamic) \n",
    "def dynamicEM():\n",
    "    global predicted_mean_dynamic, predicted_variance_dynamic, predicted_weights_dynamic\n",
    "    divergence_plot = [] # Array for plotting later\n",
    "    counter = 0 # Count iteration for printing divergence\n",
    "    \n",
    "    KL_divergence = KL_div(predicted_mean_dynamic, predicted_variance_dynamic, predicted_weights_dynamic)\n",
    "    print(\"kl div:\", KL_divergence)\n",
    "    prev_divergence = math.inf\n",
    "    \n",
    "    \n",
    "    while True:#prev_divergence - KL_divergence > 0.0001 and KL_divergence > 0:\n",
    "        \n",
    "        # This is the old implementation using python loops. I need to redo this part in numpy to optimise bc it takes too much time.\n",
    "        \"\"\"for i in range(n):\n",
    "            denominator_sum = 0\n",
    "            for j in range(k):\n",
    "                probability_matrix[i, j] = predicted_weights[j] * pdf(data[i], predicted_mean[j], predicted_variance[j])\n",
    "            \n",
    "            denominator_sum = np.sum(probability_matrix[i, :])\n",
    "            \n",
    "            probability_matrix[i, :] = probability_matrix[i, :] / denominator_sum\"\"\"\n",
    "        \n",
    "        index = counter % 1000\n",
    "        probability_matrix = calculate_p_matrix(data[index:(index + 1) * 1000], predicted_mean_dynamic, predicted_variance_dynamic, predicted_weights_dynamic)\n",
    "        # Normalise\n",
    "        probability_matrix = probability_matrix / np.sum(probability_matrix, axis = 1, keepdims=True)\n",
    "        \n",
    "        \"\"\"for j in range(k):\n",
    "            normalised_p_matrix[:, j] = probability_matrix[:, j] / np.sum(probability_matrix[:, j])\n",
    "            scaling_factor_plot[j].append(np.sum(probability_matrix[:, j]))\"\"\"\n",
    "            \n",
    "        normalised_p_matrix = probability_matrix / np.sum(probability_matrix, axis = 0, keepdims=True)\n",
    "        \n",
    "        \n",
    "        # Maximisation step\n",
    "        predicted_weights_dynamic = (1/n) * np.sum(probability_matrix, axis = 0)\n",
    "        \n",
    "        mean_matrix = (data[index:(index + 1) * 1000] * normalised_p_matrix.T).T\n",
    "        predicted_mean_dynamic = np.sum(mean_matrix, axis = 0)\n",
    "\n",
    "        predicted_variance_dynamic = np.sum(np.multiply(np.power(np.tile(data[index:(index + 1) * 1000], (k, 1)).T - predicted_mean_dynamic, 2), normalised_p_matrix), axis = 0)\n",
    "        \n",
    "        \n",
    "        diff = prev_divergence - KL_divergence\n",
    "        prev_divergence = KL_divergence\n",
    "        KL_divergence = KL_div(predicted_mean_dynamic, predicted_variance_dynamic, predicted_weights_dynamic)\n",
    "        \n",
    "        if counter % 15 == 0:\n",
    "            print(\"kl div:\", KL_divergence, \" |  iter:\", counter, \" |  difference vs the prev iter:\", diff)\n",
    "            \n",
    "            \n",
    "        divergence_plot.append(KL_divergence)\n",
    "        counter += 1\n",
    "    return divergence_plot\n",
    "\n",
    "divergence_plot = dynamicEM()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (tags/v3.10.9:1dd9be6, Dec  6 2022, 20:01:21) [MSC v.1934 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e145918ee62325bb783ae69933f229276b5458d89ab4d949d12da7376064d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
