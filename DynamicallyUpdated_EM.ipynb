{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Generate the data \n",
    "I'm aiming to generate 100000 datapoints from a Gaussian mixture model of k = 15 components. For simplicity, each datapoint is a scalar (1-dimension). \n",
    "To make it more realistic, I will random the weight of each component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 100000 # Number of datapoints\n",
    "k = 15 # Number of components\n",
    "\n",
    "# Randomising the weights\n",
    "weights = np.random.uniform(low = 0.75, high = 1, size=(k, ))\n",
    "weights = weights / np.sum(weights) \n",
    "assert abs(np.sum(weights) - 1) < 0.0000001 # Ensuring a convex linear combination\n",
    "\n",
    "# Decide which component we will sample from\n",
    "mixture_index = np.random.choice(k, size = n, replace = True, p = weights)\n",
    "assert mixture_index.shape == (n, )\n",
    "\n",
    "# Decide the random mean and variance of all 100 components\n",
    "mean = np.random.uniform(low=-12.5, high=12.5, size=(k, ))\n",
    "variance = np.random.uniform(low=0.75, high=1.5, size=(k, ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data using numpy for efficiency\n",
    "data = np.fromiter((np.random.normal(loc = mean[index], scale = np.sqrt([variance[index]])[0]) for index in mixture_index), float)\n",
    "assert data.shape == (n, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: The traditional EM algorithm\n",
    "The algorithm includes finding the probability of each point belonging to each component, then tune the mean and variance of each component according the the calculated probabilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First, define a way to calculate pdf \n",
    "\n",
    "def pdf(x, input_mean, input_var):\n",
    "    return math.exp(-0.5 * ((x - input_mean) ** 2 ) / input_var) / (math.sqrt(2 * math.pi * input_var))\n",
    "\n",
    "# Test the function\n",
    "assert pdf(0, 0, 1) == 0.3989422804014327\n",
    "assert pdf(0.5, 0, 1) == 0.3520653267642995\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using numpy to calculate pdf, and then normalise it across k components\n",
    "def calculate_p_matrix(x, input_mean, input_var, input_weight):\n",
    "    # Duplicate data so dimensions work out\n",
    "    mean_matrix = np.tile(input_mean, (n, 1)).T\n",
    "    variance_matrix = np.tile(input_var, (n, 1)).T\n",
    "    weight_matrix = np.tile(input_weight, (n, 1)).T\n",
    "    \n",
    "    # PDF calculation\n",
    "    p_matrix = weight_matrix * np.exp(-0.5 * np.power(x - mean_matrix, 2) / variance_matrix) / (np.sqrt(2 * np.pi * variance_matrix))\n",
    "    \n",
    "    p_matrix = p_matrix.transpose(1, 0)\n",
    "    \n",
    "    return p_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new [0.07289326 0.03680669 0.00373709 ... 0.07845436 0.00905348 0.07705684]\n",
      "old [0.07289326 0.03680669 0.00373709 ... 0.07845436 0.00905348 0.07705684]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a metric to evaluate our return from EM alg.\n",
    "# Hardcoded P_value to save time\n",
    "\n",
    "\n",
    "# Old implementation\n",
    "\n",
    "old_P_value = np.zeros((n,))\n",
    "for i in range(n):\n",
    "    for j in range(k):\n",
    "        old_P_value[i] += weights[j] * pdf(data[i], mean[j], variance[j])\n",
    "\n",
    "\n",
    "# New implementation with numpy, more efficient\n",
    "P_value = np.sum(calculate_p_matrix(data, mean, variance, weights), axis = 1)\n",
    "   \n",
    "print(\"new\", P_value)\n",
    "print(\"old\", old_P_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# KL divergence is an integral from -inf to +inf, in this case, I only use the n datapoints that we already generated.\n",
    "\n",
    "    \n",
    "def KL_div(pred_mean, pred_variance, pred_weights):\n",
    "    # Old implementation\n",
    "    \"\"\"KL_divergence = 0\n",
    "    for i in range(n):\n",
    "        Q_value = 0\n",
    "        for j in range(k):\n",
    "            Q_value += pred_weights[j] * pdf(data[i], pred_mean[j], pred_variance[j])\n",
    "            #P_value += weights[j] * pdf(data[i], mean[j], variance[j])\n",
    "        KL_divergence += P_value[i] * math.log(P_value[i]/Q_value, math.e) - P_value[i] + Q_value\"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    # New implementation\n",
    "    Q_value = np.sum(calculate_p_matrix(data, pred_mean, pred_variance, pred_weights), axis = 1)\n",
    "    \n",
    "    KL_divergence = np.sum(P_value * np.log(P_value / Q_value) - P_value + Q_value)\n",
    "    \n",
    "    return KL_divergence\n",
    "    \n",
    "assert KL_div(mean, variance, weights) == 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This implementation is based on Dr. Martha White's notes for CMPUT367, page 107. \n",
    "\n",
    "\"\"\"scaling_factor_plot = [[] for j in range(k)]\n",
    "print(scaling_factor_plot)\n",
    "\"\"\"\n",
    "# Starts with random means, variances and weights\n",
    "predicted_mean = np.random.uniform(low=-5, high=5, size=(k, ))\n",
    "predicted_variance = np.random.uniform(low=0.5, high=5, size=(k, ))\n",
    "predicted_weights = np.random.random(size=(k, ))\n",
    "predicted_weights = predicted_weights / np.sum(predicted_weights) \n",
    "\n",
    "def traditional_EM():\n",
    "    \n",
    "    divergence_plot = [] # Array for plotting later\n",
    "    counter = 0 # Count iteration for printing divergence\n",
    "    \n",
    "    KL_divergence = KL_div(predicted_mean, predicted_variance, predicted_weights)\n",
    "    print(\"kl div:\", KL_divergence)\n",
    "    prev_divergence = math.inf\n",
    "    \n",
    "    probability_matrix = np.zeros((n, k))\n",
    "    normalised_p_matrix = np.zeros((n, k))\n",
    "    \n",
    "    while prev_divergence - KL_divergence > 0.0001 and KL_divergence > 0:\n",
    "        \n",
    "        # This is the old implementation using python loops. I need to redo this part in numpy to optimise bc it takes too much time.\n",
    "        \"\"\"for i in range(n):\n",
    "            denominator_sum = 0\n",
    "            for j in range(k):\n",
    "                probability_matrix[i, j] = predicted_weights[j] * pdf(data[i], predicted_mean[j], predicted_variance[j])\n",
    "            \n",
    "            denominator_sum = np.sum(probability_matrix[i, :])\n",
    "            \n",
    "            probability_matrix[i, :] = probability_matrix[i, :] / denominator_sum\"\"\"\n",
    "        \n",
    "        probability_matrix = calculate_p_matrix(data, predicted_mean, predicted_variance, predicted_weights)\n",
    "        # Normalise\n",
    "        probability_matrix = probability_matrix / np.sum(probability_matrix, axis = 1, keepdims=True)\n",
    "        \n",
    "        \"\"\"for j in range(k):\n",
    "            normalised_p_matrix[:, j] = probability_matrix[:, j] / np.sum(probability_matrix[:, j])\n",
    "            scaling_factor_plot[j].append(np.sum(probability_matrix[:, j]))\"\"\"\n",
    "            \n",
    "        normalised_p_matrix = probability_matrix / np.sum(probability_matrix, axis = 0, keepdims=True)\n",
    "                \n",
    "        for j in range(k):\n",
    "            \n",
    "            predicted_weights[j] = (1/n) * np.sum(probability_matrix[:, j])\n",
    "            predicted_mean[j] = np.sum(normalised_p_matrix[:, j] * data)\n",
    "            \n",
    "            predicted_variance[j] = np.sum(normalised_p_matrix[:, j] * (data - predicted_mean[j]) ** 2)\n",
    "        \n",
    "        diff = prev_divergence - KL_divergence\n",
    "        prev_divergence = KL_divergence\n",
    "        KL_divergence = KL_div(predicted_mean, predicted_variance, predicted_weights)\n",
    "        \n",
    "        if counter % 5 == 0:\n",
    "            print(\"kl div:\", KL_divergence, \" |  iter:\", counter, \" |  difference vs the prev iter:\", diff)\n",
    "            \n",
    "            \n",
    "        divergence_plot.append(KL_divergence)\n",
    "        counter += 1\n",
    "    return predicted_mean, predicted_variance, predicted_weights, divergence_plot\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kl div: 10717.143154638532\n",
      "kl div: 267.6963038922512  |  iter: 0  |  difference vs the prev iter: inf\n",
      "kl div: 121.93970763638545  |  iter: 5  |  difference vs the prev iter: 26.981585105834455\n",
      "kl div: 29.703686929233687  |  iter: 10  |  difference vs the prev iter: 14.423486922595814\n",
      "kl div: 12.823543592678584  |  iter: 15  |  difference vs the prev iter: 1.8004466075726704\n",
      "kl div: 10.611285550566867  |  iter: 20  |  difference vs the prev iter: 0.2811214024631763\n",
      "kl div: 9.881068018813275  |  iter: 25  |  difference vs the prev iter: 0.13286751134123165\n",
      "kl div: 8.930528025806098  |  iter: 30  |  difference vs the prev iter: 0.21229484447732716\n",
      "kl div: 6.979570888657124  |  iter: 35  |  difference vs the prev iter: 0.4427535564339431\n",
      "kl div: 4.952663230685455  |  iter: 40  |  difference vs the prev iter: 0.3609194075147313\n",
      "kl div: 4.173414424182849  |  iter: 45  |  difference vs the prev iter: 0.11557592338458722\n",
      "kl div: 3.914879025502141  |  iter: 50  |  difference vs the prev iter: 0.041171217137398575\n",
      "kl div: 3.7940053996056915  |  iter: 55  |  difference vs the prev iter: 0.021241096380762325\n",
      "kl div: 3.714309953549953  |  iter: 60  |  difference vs the prev iter: 0.014963552277095449\n",
      "kl div: 3.64990890070629  |  iter: 65  |  difference vs the prev iter: 0.012462234427921715\n",
      "kl div: 3.593026857143521  |  iter: 70  |  difference vs the prev iter: 0.01114023914254103\n",
      "kl div: 3.540889261800221  |  iter: 75  |  difference vs the prev iter: 0.010264508918176318\n",
      "kl div: 3.4922439990250664  |  iter: 80  |  difference vs the prev iter: 0.009603391071188572\n",
      "kl div: 3.4463866701308405  |  iter: 85  |  difference vs the prev iter: 0.009068688852016837\n",
      "kl div: 3.402859957850112  |  iter: 90  |  difference vs the prev iter: 0.00861809811554659\n",
      "kl div: 3.361344870713465  |  iter: 95  |  difference vs the prev iter: 0.008226819827330534\n",
      "kl div: 3.3216121342993077  |  iter: 100  |  difference vs the prev iter: 0.007878345189644698\n",
      "kl div: 3.283495404597344  |  iter: 105  |  difference vs the prev iter: 0.007560951461261123\n",
      "kl div: 3.2468740082439522  |  iter: 110  |  difference vs the prev iter: 0.0072660921928249245\n",
      "kl div: 3.211660701853095  |  iter: 115  |  difference vs the prev iter: 0.006987511085495779\n",
      "kl div: 3.1777925183214637  |  iter: 120  |  difference vs the prev iter: 0.006720679396203355\n",
      "kl div: 3.1452237337389763  |  iter: 125  |  difference vs the prev iter: 0.006462401242343763\n",
      "kl div: 3.1139204031148697  |  iter: 130  |  difference vs the prev iter: 0.006210517598569609\n",
      "kl div: 3.083856115611136  |  iter: 135  |  difference vs the prev iter: 0.005963674129511709\n",
      "kl div: 3.0550087285256518  |  iter: 140  |  difference vs the prev iter: 0.005721133765389297\n",
      "kl div: 3.027357902749817  |  iter: 145  |  difference vs the prev iter: 0.005482622773642198\n",
      "kl div: 3.000883300549584  |  iter: 150  |  difference vs the prev iter: 0.005248203345072255\n",
      "kl div: 2.975563331266277  |  iter: 155  |  difference vs the prev iter: 0.005018168314570914\n",
      "kl div: 2.951374346784612  |  iter: 160  |  difference vs the prev iter: 0.004792954879782041\n",
      "kl div: 2.928290200553294  |  iter: 165  |  difference vs the prev iter: 0.004573075193408105\n",
      "kl div: 2.9062820935491107  |  iter: 170  |  difference vs the prev iter: 0.004359061892536431\n",
      "kl div: 2.8853186390805576  |  iter: 175  |  difference vs the prev iter: 0.004151426933061586\n",
      "kl div: 2.8653660864695545  |  iter: 180  |  difference vs the prev iter: 0.003950632061338055\n",
      "kl div: 2.846388651843141  |  iter: 185  |  difference vs the prev iter: 0.003757069349037412\n",
      "kl div: 2.8283489123505943  |  iter: 190  |  difference vs the prev iter: 0.0035710501252044224\n",
      "kl div: 2.8112082281253596  |  iter: 195  |  difference vs the prev iter: 0.0033928007210377586\n",
      "kl div: 2.7949271639617788  |  iter: 200  |  difference vs the prev iter: 0.003222463528153252\n",
      "kl div: 2.779465889804007  |  iter: 205  |  difference vs the prev iter: 0.003060101981363861\n",
      "kl div: 2.7647845454739692  |  iter: 210  |  difference vs the prev iter: 0.0029057081729106926\n",
      "kl div: 2.7508435606506914  |  iter: 215  |  difference vs the prev iter: 0.002759212100046149\n",
      "kl div: 2.737603925674689  |  iter: 220  |  difference vs the prev iter: 0.0026204916007754875\n",
      "kl div: 2.725027412417601  |  iter: 225  |  difference vs the prev iter: 0.002489382331944956\n",
      "kl div: 2.7130767471752524  |  iter: 230  |  difference vs the prev iter: 0.0023656872233042137\n",
      "kl div: 2.7017157395793343  |  iter: 235  |  difference vs the prev iter: 0.0022491851276136288\n",
      "kl div: 2.6909093725705873  |  iter: 240  |  difference vs the prev iter: 0.0021396383571832267\n",
      "kl div: 2.6806238592713814  |  iter: 245  |  difference vs the prev iter: 0.0020367990844896156\n",
      "kl div: 2.670826672542391  |  iter: 250  |  difference vs the prev iter: 0.0019404145680042006\n",
      "kl div: 2.6614865529295484  |  iter: 255  |  difference vs the prev iter: 0.001850231260791091\n",
      "kl div: 2.652573500094116  |  iter: 260  |  difference vs the prev iter: 0.001765997902222427\n",
      "kl div: 2.644058752290798  |  iter: 265  |  difference vs the prev iter: 0.001687467751179561\n",
      "kl div: 2.6359147576227926  |  iter: 270  |  difference vs the prev iter: 0.0016144001036910716\n",
      "kl div: 2.6281151401392315  |  iter: 275  |  difference vs the prev iter: 0.0015465611752354391\n",
      "kl div: 2.6206346631417685  |  iter: 280  |  difference vs the prev iter: 0.0014837246197187959\n",
      "kl div: 2.613449191358688  |  iter: 285  |  difference vs the prev iter: 0.0014256716691325444\n",
      "kl div: 2.606535653199633  |  iter: 290  |  difference vs the prev iter: 0.00137219108543718\n",
      "kl div: 2.599872003781634  |  iter: 295  |  difference vs the prev iter: 0.001323078997738314\n",
      "kl div: 2.5934371890749697  |  iter: 300  |  difference vs the prev iter: 0.001278138644235316\n",
      "kl div: 2.5872111113465106  |  iter: 305  |  difference vs the prev iter: 0.0012371801299551066\n",
      "kl div: 2.581174595781849  |  iter: 310  |  difference vs the prev iter: 0.0012000201833473056\n",
      "kl div: 2.575309358219344  |  iter: 315  |  difference vs the prev iter: 0.0011664819526404635\n",
      "kl div: 2.5695979738095596  |  iter: 320  |  difference vs the prev iter: 0.0011363948178026995\n",
      "kl div: 2.5640238464510836  |  iter: 325  |  difference vs the prev iter: 0.0011095942298799955\n",
      "kl div: 2.558571178992935  |  iter: 330  |  difference vs the prev iter: 0.0010859215878920025\n",
      "kl div: 2.553224944181587  |  iter: 335  |  difference vs the prev iter: 0.0010652240605448782\n",
      "kl div: 2.5479708564813874  |  iter: 340  |  difference vs the prev iter: 0.001047354414882573\n",
      "kl div: 2.5427953450572027  |  iter: 345  |  difference vs the prev iter: 0.0010321707649905143\n",
      "kl div: 2.5376855282533928  |  iter: 350  |  difference vs the prev iter: 0.0010195362782785544\n",
      "kl div: 2.5326291900585507  |  iter: 355  |  difference vs the prev iter: 0.0010093187235806766\n",
      "kl div: 2.527614759176474  |  iter: 360  |  difference vs the prev iter: 0.0010013899522420822\n",
      "kl div: 2.5226312913560966  |  iter: 365  |  difference vs the prev iter: 0.0009956252010638877\n",
      "kl div: 2.5176684557747806  |  iter: 370  |  difference vs the prev iter: 0.00099190226121193\n",
      "kl div: 2.512716526280821  |  iter: 375  |  difference vs the prev iter: 0.0009901004604015995\n",
      "kl div: 2.5077663783451865  |  iter: 380  |  difference vs the prev iter: 0.0009900995009464175\n",
      "kl div: 2.5028094925085966  |  iter: 385  |  difference vs the prev iter: 0.0009917781221679967\n",
      "kl div: 2.4978379650638556  |  iter: 390  |  difference vs the prev iter: 0.000995012621901381\n",
      "kl div: 2.492844526531697  |  iter: 395  |  difference vs the prev iter: 0.0009996752854779523\n",
      "kl div: 2.487822568251066  |  iter: 400  |  difference vs the prev iter: 0.0010056327608234383\n",
      "kl div: 2.4827661770362472  |  iter: 405  |  difference vs the prev iter: 0.001012744433873003\n",
      "kl div: 2.4776701774014165  |  iter: 410  |  difference vs the prev iter: 0.0010208609651418676\n",
      "kl div: 2.4725301802254545  |  iter: 415  |  difference vs the prev iter: 0.0010298230418568366\n",
      "kl div: 2.4673426360125164  |  iter: 420  |  difference vs the prev iter: 0.001039460557145766\n",
      "kl div: 2.4621048900589266  |  iter: 425  |  difference vs the prev iter: 0.0010495923329383317\n",
      "kl div: 2.4568152359018067  |  iter: 430  |  difference vs the prev iter: 0.001060026650774315\n",
      "kl div: 2.45147296250147  |  iter: 435  |  difference vs the prev iter: 0.0010705626783522604\n",
      "kl div: 2.446078389756653  |  iter: 440  |  difference vs the prev iter: 0.001080993038646838\n",
      "kl div: 2.4406328862342384  |  iter: 445  |  difference vs the prev iter: 0.0010911076255473162\n",
      "kl div: 2.435138862732325  |  iter: 450  |  difference vs the prev iter: 0.0011006986883503878\n",
      "kl div: 2.4295997353740297  |  iter: 455  |  difference vs the prev iter: 0.0011095671733807322\n",
      "kl div: 2.4240198527034313  |  iter: 460  |  difference vs the prev iter: 0.001117530131100164\n",
      "kl div: 2.418404382793116  |  iter: 465  |  difference vs the prev iter: 0.0011244288321203832\n",
      "kl div: 2.4127591585639734  |  iter: 470  |  difference vs the prev iter: 0.001130137163192213\n",
      "kl div: 2.407090482561593  |  iter: 475  |  difference vs the prev iter: 0.0011345696338951328\n",
      "kl div: 2.4014048959345025  |  iter: 480  |  difference vs the prev iter: 0.0011376882822822232\n",
      "kl div: 2.395708920291918  |  iter: 485  |  difference vs the prev iter: 0.0011395076924523018\n",
      "kl div: 2.3900087848512452  |  iter: 490  |  difference vs the prev iter: 0.001140097373525606\n",
      "kl div: 2.3843101546994934  |  iter: 495  |  difference vs the prev iter: 0.001139580863683154\n",
      "kl div: 2.3786178784576752  |  iter: 500  |  difference vs the prev iter: 0.0011381310829170488\n",
      "kl div: 2.372935774893406  |  iter: 505  |  difference vs the prev iter: 0.0011359617584516535\n",
      "kl div: 2.3672664778996775  |  iter: 510  |  difference vs the prev iter: 0.0011333149817698285\n",
      "kl div: 2.361611357550221  |  iter: 515  |  difference vs the prev iter: 0.0011304453272411585\n",
      "kl div: 2.3559705319247097  |  iter: 520  |  difference vs the prev iter: 0.0011276011625560578\n",
      "kl div: 2.350342980254485  |  iter: 525  |  difference vs the prev iter: 0.0011250040505434988\n",
      "kl div: 2.3447267628921304  |  iter: 530  |  difference vs the prev iter: 0.0011228272391132776\n",
      "kl div: 2.339119348236575  |  iter: 535  |  difference vs the prev iter: 0.0011211743519656814\n",
      "kl div: 2.3335180410811476  |  iter: 540  |  difference vs the prev iter: 0.0011200594268867547\n",
      "kl div: 2.3279205010171973  |  iter: 545  |  difference vs the prev iter: 0.0011193894414964767\n",
      "kl div: 2.3223253334674796  |  iter: 550  |  difference vs the prev iter: 0.00111895059159961\n",
      "kl div: 2.3167327293029203  |  iter: 555  |  difference vs the prev iter: 0.0011183996541195285\n",
      "kl div: 2.311145121264154  |  iter: 560  |  difference vs the prev iter: 0.0011172620147528178\n",
      "kl div: 2.3055678165283693  |  iter: 565  |  difference vs the prev iter: 0.0011149382362103388\n",
      "kl div: 2.300009554349698  |  iter: 570  |  difference vs the prev iter: 0.0011107212588337134\n",
      "kl div: 2.2944829265975724  |  iter: 575  |  difference vs the prev iter: 0.001103826472246272\n",
      "kl div: 2.2890045887545765  |  iter: 580  |  difference vs the prev iter: 0.0010934366878054824\n",
      "kl div: 2.2835951823191283  |  iter: 585  |  difference vs the prev iter: 0.0010787630720900943\n",
      "kl div: 2.278278890378316  |  iter: 590  |  difference vs the prev iter: 0.0010591215486925876\n",
      "kl div: 2.2730825616422683  |  iter: 595  |  difference vs the prev iter: 0.001034021355761805\n",
      "kl div: 2.268034368302334  |  iter: 600  |  difference vs the prev iter: 0.0010032590379962514\n",
      "kl div: 2.2631620123976837  |  iter: 605  |  difference vs the prev iter: 0.0009670072099727811\n",
      "kl div: 2.2584905618839857  |  iter: 610  |  difference vs the prev iter: 0.0009258841928438954\n",
      "kl div: 2.2540400731383556  |  iter: 615  |  difference vs the prev iter: 0.0008809892217036541\n",
      "kl div: 2.2498232272753462  |  iter: 620  |  difference vs the prev iter: 0.0008338895817403547\n",
      "kl div: 2.245843254531592  |  iter: 625  |  difference vs the prev iter: 0.0007865515625673503\n",
      "kl div: 2.2420924266524684  |  iter: 630  |  difference vs the prev iter: 0.0007412159269537533\n",
      "kl div: 2.2385513508839643  |  iter: 635  |  difference vs the prev iter: 0.0007002294749649529\n",
      "kl div: 2.2351892026480153  |  iter: 640  |  difference vs the prev iter: 0.0006658536816464\n",
      "kl div: 2.231964903956337  |  iter: 645  |  difference vs the prev iter: 0.0006400775325188235\n",
      "kl div: 2.2288291179648327  |  iter: 650  |  difference vs the prev iter: 0.0006244615643820062\n",
      "kl div: 2.22572681763698  |  iter: 655  |  difference vs the prev iter: 0.0006200342196938102\n",
      "kl div: 2.2226001212818067  |  iter: 660  |  difference vs the prev iter: 0.0006272513335274787\n",
      "kl div: 2.2193910806622497  |  iter: 665  |  difference vs the prev iter: 0.0006460178442915243\n",
      "kl div: 2.2160441526207717  |  iter: 670  |  difference vs the prev iter: 0.0006757607773097973\n",
      "kl div: 2.2125081663524315  |  iter: 675  |  difference vs the prev iter: 0.000715536127108507\n",
      "kl div: 2.20873769332441  |  iter: 680  |  difference vs the prev iter: 0.0007641505172157892\n",
      "kl div: 2.2046938153782305  |  iter: 685  |  difference vs the prev iter: 0.0008202804693668853\n",
      "kl div: 2.2003443549433177  |  iter: 690  |  difference vs the prev iter: 0.000882576511655131\n",
      "kl div: 2.1956636736777844  |  iter: 695  |  difference vs the prev iter: 0.0009497447938673353\n",
      "kl div: 2.1906321630422148  |  iter: 700  |  difference vs the prev iter: 0.0010206036458804135\n",
      "kl div: 2.185235547584826  |  iter: 705  |  difference vs the prev iter: 0.0010941164123292602\n",
      "kl div: 2.179464105883016  |  iter: 710  |  difference vs the prev iter: 0.0011694040153202856\n",
      "kl div: 2.173311891790197  |  iter: 715  |  difference vs the prev iter: 0.0012457419893077137\n",
      "kl div: 2.166776014976116  |  iter: 720  |  difference vs the prev iter: 0.0013225466298343314\n",
      "kl div: 2.1598560182525555  |  iter: 725  |  difference vs the prev iter: 0.0013993544582899808\n",
      "kl div: 2.152553371334601  |  iter: 730  |  difference vs the prev iter: 0.0014757983824131848\n",
      "kl div: 2.1448710873206345  |  iter: 735  |  difference vs the prev iter: 0.001551583113758248\n",
      "kl div: 2.136813458719936  |  iter: 740  |  difference vs the prev iter: 0.0016264614611918304\n",
      "kl div: 2.1283859038322546  |  iter: 745  |  difference vs the prev iter: 0.001700212746220231\n",
      "kl div: 2.1195949107710392  |  iter: 750  |  difference vs the prev iter: 0.0017726237906807718\n",
      "kl div: 2.1104480646633044  |  iter: 755  |  difference vs the prev iter: 0.001843472894886844\n",
      "kl div: 2.1009541428867258  |  iter: 760  |  difference vs the prev iter: 0.0019125168336211473\n",
      "kl div: 2.0911232631928507  |  iter: 765  |  difference vs the prev iter: 0.0019794808816597786\n",
      "kl div: 2.0809670696831555  |  iter: 770  |  difference vs the prev iter: 0.0020440518418984865\n",
      "kl div: 2.070498941922603  |  iter: 775  |  difference vs the prev iter: 0.002105874004126651\n",
      "kl div: 2.0597342125781064  |  iter: 780  |  difference vs the prev iter: 0.0021645480228240643\n",
      "kl div: 2.0486903791659867  |  iter: 785  |  difference vs the prev iter: 0.0022196326664980504\n",
      "kl div: 2.037387295526863  |  iter: 790  |  difference vs the prev iter: 0.002270649450591744\n",
      "kl div: 2.0258473289719316  |  iter: 795  |  difference vs the prev iter: 0.0023170900564655206\n",
      "kl div: 2.014095469447174  |  iter: 800  |  difference vs the prev iter: 0.002358426462850005\n",
      "kl div: 2.002159377984804  |  iter: 805  |  difference vs the prev iter: 0.0023941235811206774\n",
      "kl div: 1.990069363131042  |  iter: 810  |  difference vs the prev iter: 0.002423654092003291\n",
      "kl div: 1.977858276105356  |  iter: 815  |  difference vs the prev iter: 0.0024465150118941903\n",
      "kl div: 1.9655613182312612  |  iter: 820  |  difference vs the prev iter: 0.0024622454672513783\n",
      "kl div: 1.9532157577121607  |  iter: 825  |  difference vs the prev iter: 0.002470444865328769\n",
      "kl div: 1.9408605568989248  |  iter: 830  |  difference vs the prev iter: 0.0024707906928091994\n",
      "kl div: 1.928535915802073  |  iter: 835  |  difference vs the prev iter: 0.002463054946182597\n",
      "kl div: 1.9162827422873485  |  iter: 840  |  difference vs the prev iter: 0.0024471183175933664\n",
      "kl div: 1.9041420640397302  |  iter: 845  |  difference vs the prev iter: 0.002422981156462889\n",
      "kl div: 1.8921544013733653  |  iter: 850  |  difference vs the prev iter: 0.002390770481093707\n",
      "kl div: 1.8803591231592656  |  iter: 855  |  difference vs the prev iter: 0.002350742427821295\n",
      "kl div: 1.8687938100745052  |  iter: 860  |  difference vs the prev iter: 0.002303279783357981\n",
      "kl div: 1.8574936498320782  |  iter: 865  |  difference vs the prev iter: 0.0022488846299095755\n",
      "kl div: 1.8464908879382576  |  iter: 870  |  difference vs the prev iter: 0.002188166306018813\n",
      "kl div: 1.8358143549608055  |  iter: 875  |  difference vs the prev iter: 0.0021218253353929573\n",
      "kl div: 1.825489087196395  |  iter: 880  |  difference vs the prev iter: 0.0020506341362709346\n",
      "kl div: 1.8155360527113533  |  iter: 885  |  difference vs the prev iter: 0.001975415551787929\n",
      "kl div: 1.8059719891013266  |  iter: 890  |  difference vs the prev iter: 0.0018970203567265642\n",
      "kl div: 1.7968093534912901  |  iter: 895  |  difference vs the prev iter: 0.0018163048712862562\n",
      "kl div: 1.7880563799393414  |  iter: 900  |  difference vs the prev iter: 0.0017341097519325555\n",
      "kl div: 1.7797172345691201  |  iter: 905  |  difference vs the prev iter: 0.0016512409169451292\n",
      "kl div: 1.771792255064924  |  iter: 910  |  difference vs the prev iter: 0.0015684532405459972\n",
      "kl div: 1.7642782585551016  |  iter: 915  |  difference vs the prev iter: 0.001486437564222065\n",
      "kl div: 1.7571689005690152  |  iter: 920  |  difference vs the prev iter: 0.0014058111724994937\n",
      "kl div: 1.7504550675807726  |  iter: 925  |  difference vs the prev iter: 0.0013271117734983129\n",
      "kl div: 1.7441252864629238  |  iter: 930  |  difference vs the prev iter: 0.0012507947681108522\n",
      "kl div: 1.7381661358178881  |  iter: 935  |  difference vs the prev iter: 0.0011772334370179216\n",
      "kl div: 1.7325626463081683  |  iter: 940  |  difference vs the prev iter: 0.0011067216272226954\n",
      "kl div: 1.7272986796093321  |  iter: 945  |  difference vs the prev iter: 0.0010394783870233404\n",
      "kl div: 1.7223572781888812  |  iter: 950  |  difference vs the prev iter: 0.000975654085759059\n",
      "kl div: 1.7177209805873093  |  iter: 955  |  difference vs the prev iter: 0.0009153374831805117\n",
      "kl div: 1.7133720991773047  |  iter: 960  |  difference vs the prev iter: 0.0008585633171669382\n",
      "kl div: 1.7092929592718316  |  iter: 965  |  difference vs the prev iter: 0.0008053200543822747\n",
      "kl div: 1.7054661001283722  |  iter: 970  |  difference vs the prev iter: 0.0007555574658963948\n",
      "kl div: 1.7018744395597767  |  iter: 975  |  difference vs the prev iter: 0.0007091938199004222\n",
      "kl div: 1.6985014047724607  |  iter: 980  |  difference vs the prev iter: 0.0006661225187403197\n",
      "kl div: 1.6953310326538604  |  iter: 985  |  difference vs the prev iter: 0.0006262180796401395\n",
      "kl div: 1.692348042970595  |  iter: 990  |  difference vs the prev iter: 0.0005893413994066954\n",
      "kl div: 1.6895378881075447  |  iter: 995  |  difference vs the prev iter: 0.0005553443154795445\n",
      "kl div: 1.686886782849629  |  iter: 1000  |  difference vs the prev iter: 0.0005240734447538031\n",
      "kl div: 1.684381717558286  |  iter: 1005  |  difference vs the prev iter: 0.0004953733880781463\n",
      "kl div: 1.6820104577906922  |  iter: 1010  |  difference vs the prev iter: 0.00046908931264177944\n",
      "kl div: 1.67976153313369  |  iter: 1015  |  difference vs the prev iter: 0.00044506901480523275\n",
      "kl div: 1.6776242176484029  |  iter: 1020  |  difference vs the prev iter: 0.00042316449420742863\n",
      "kl div: 1.6755885040511231  |  iter: 1025  |  difference vs the prev iter: 0.00040323313933909866\n",
      "kl div: 1.673645073344615  |  iter: 1030  |  difference vs the prev iter: 0.0003851385677551278\n",
      "kl div: 1.671785261420746  |  iter: 1035  |  difference vs the prev iter: 0.00036875117432977333\n",
      "kl div: 1.6700010238133094  |  iter: 1040  |  difference vs the prev iter: 0.0003539484618713118\n",
      "kl div: 1.6682848995622785  |  iter: 1045  |  difference vs the prev iter: 0.0003406151837019866\n",
      "kl div: 1.6666299749837976  |  iter: 1050  |  difference vs the prev iter: 0.0003286433265161648\n",
      "kl div: 1.6650298478929662  |  iter: 1055  |  difference vs the prev iter: 0.00031793201732543963\n",
      "kl div: 1.6634785927529294  |  iter: 1060  |  difference vs the prev iter: 0.00030838729652282737\n",
      "kl div: 1.661970727060705  |  iter: 1065  |  difference vs the prev iter: 0.00029992188247596197\n",
      "kl div: 1.6605011791723434  |  iter: 1070  |  difference vs the prev iter: 0.00029245486216278316\n",
      "kl div: 1.6590652577498648  |  iter: 1075  |  difference vs the prev iter: 0.00028591137604117023\n",
      "kl div: 1.6576586228508365  |  iter: 1080  |  difference vs the prev iter: 0.0002802222698328194\n",
      "kl div: 1.6562772587566965  |  iter: 1085  |  difference vs the prev iter: 0.0002753237609345316\n",
      "kl div: 1.6549174484689415  |  iter: 1090  |  difference vs the prev iter: 0.00027115709602565374\n",
      "kl div: 1.6535757498780121  |  iter: 1095  |  difference vs the prev iter: 0.00026766822557666714\n",
      "kl div: 1.65224897354444  |  iter: 1100  |  difference vs the prev iter: 0.0002648074800868372\n",
      "kl div: 1.650934161998327  |  iter: 1105  |  difference vs the prev iter: 0.00026252926888092887\n",
      "kl div: 1.649628570507555  |  iter: 1110  |  difference vs the prev iter: 0.0002607917904953183\n",
      "kl div: 1.6483296492149857  |  iter: 1115  |  difference vs the prev iter: 0.0002595567654952724\n",
      "kl div: 1.6470350265604436  |  iter: 1120  |  difference vs the prev iter: 0.00025878917362898157\n",
      "kl div: 1.6457424939010157  |  iter: 1125  |  difference vs the prev iter: 0.000258457032385806\n",
      "kl div: 1.6444499912480501  |  iter: 1130  |  difference vs the prev iter: 0.0002585311623779507\n",
      "kl div: 1.6431555940239686  |  iter: 1135  |  difference vs the prev iter: 0.0002589849936780464\n",
      "kl div: 1.6418575007832132  |  iter: 1140  |  difference vs the prev iter: 0.00025979438004108957\n",
      "kl div: 1.6405540217890309  |  iter: 1145  |  difference vs the prev iter: 0.0002609374201540948\n",
      "kl div: 1.6392435684033908  |  iter: 1150  |  difference vs the prev iter: 0.00026239430780505835\n",
      "kl div: 1.6379246431996222  |  iter: 1155  |  difference vs the prev iter: 0.0002641471845017396\n",
      "kl div: 1.636595830741398  |  iter: 1160  |  difference vs the prev iter: 0.0002661800119525548\n",
      "kl div: 1.6352557889663497  |  iter: 1165  |  difference vs the prev iter: 0.00026847845039634777\n",
      "kl div: 1.6339032411092311  |  iter: 1170  |  difference vs the prev iter: 0.0002710297554979757\n",
      "kl div: 1.6325369681229858  |  iter: 1175  |  difference vs the prev iter: 0.00027382267713349506\n",
      "kl div: 1.6311558015268475  |  iter: 1180  |  difference vs the prev iter: 0.00027684738405664433\n",
      "kl div: 1.6297586166534983  |  iter: 1185  |  difference vs the prev iter: 0.00028009537881024116\n",
      "kl div: 1.628344326220183  |  iter: 1190  |  difference vs the prev iter: 0.00028355943519042803\n",
      "kl div: 1.6269118742063822  |  iter: 1195  |  difference vs the prev iter: 0.0002872335382138047\n",
      "kl div: 1.6254602299743586  |  iter: 1200  |  difference vs the prev iter: 0.0002911128480247438\n",
      "kl div: 1.6239883825945594  |  iter: 1205  |  difference vs the prev iter: 0.0002951936423682966\n",
      "kl div: 1.6224953353345808  |  iter: 1210  |  difference vs the prev iter: 0.0002994733061549848\n",
      "kl div: 1.6209801002643158  |  iter: 1215  |  difference vs the prev iter: 0.00030395028671592605\n",
      "kl div: 1.6194416929498587  |  iter: 1220  |  difference vs the prev iter: 0.0003086240980867405\n",
      "kl div: 1.6178791271586301  |  iter: 1225  |  difference vs the prev iter: 0.00031349531495572514\n",
      "kl div: 1.6162914095731507  |  iter: 1230  |  difference vs the prev iter: 0.0003185655617421457\n",
      "kl div: 1.614677534439057  |  iter: 1235  |  difference vs the prev iter: 0.00032383754481557503\n",
      "kl div: 1.6130364781046866  |  iter: 1240  |  difference vs the prev iter: 0.0003293150615071294\n",
      "kl div: 1.6113671934102478  |  iter: 1245  |  difference vs the prev iter: 0.0003350030412565541\n",
      "kl div: 1.6096686038621841  |  iter: 1250  |  difference vs the prev iter: 0.0003409075886617874\n",
      "kl div: 1.6079395975355637  |  iter: 1255  |  difference vs the prev iter: 0.0003470360389234983\n",
      "kl div: 1.6061790206513353  |  iter: 1260  |  difference vs the prev iter: 0.00035339702373171633\n",
      "kl div: 1.6043856707493847  |  iter: 1265  |  difference vs the prev iter: 0.0003600005615835844\n",
      "kl div: 1.6025582893939336  |  iter: 1270  |  difference vs the prev iter: 0.0003668581458979858\n",
      "kl div: 1.6006955543094052  |  iter: 1275  |  difference vs the prev iter: 0.0003739828685926927\n",
      "kl div: 1.5987960708958355  |  iter: 1280  |  difference vs the prev iter: 0.0003813895469686468\n",
      "kl div: 1.596858362985937  |  iter: 1285  |  difference vs the prev iter: 0.0003890948759461832\n",
      "kl div: 1.5948808627630886  |  iter: 1290  |  difference vs the prev iter: 0.0003971176024109013\n",
      "kl div: 1.5928618997083304  |  iter: 1295  |  difference vs the prev iter: 0.0004054787255249881\n",
      "kl div: 1.5907996884614888  |  iter: 1300  |  difference vs the prev iter: 0.00041420171781347825\n",
      "kl div: 1.5886923154372057  |  iter: 1305  |  difference vs the prev iter: 0.00042331278182761167\n",
      "kl div: 1.5865377240566816  |  iter: 1310  |  difference vs the prev iter: 0.00043284112871444513\n",
      "kl div: 1.584333698411363  |  iter: 1315  |  difference vs the prev iter: 0.000442819305684905\n",
      "kl div: 1.5820778451962474  |  iter: 1320  |  difference vs the prev iter: 0.00045328354290585793\n",
      "kl div: 1.5797675736899732  |  iter: 1325  |  difference vs the prev iter: 0.00046427415721517207\n",
      "kl div: 1.5774000735930707  |  iter: 1330  |  difference vs the prev iter: 0.0004758359882230945\n",
      "kl div: 1.5749722905052297  |  iter: 1335  |  difference vs the prev iter: 0.00048801887459171134\n",
      "kl div: 1.5724808987877936  |  iter: 1340  |  difference vs the prev iter: 0.0005008781952871022\n",
      "kl div: 1.5699222716244194  |  iter: 1345  |  difference vs the prev iter: 0.0005144754287280673\n",
      "kl div: 1.5672924480029018  |  iter: 1350  |  difference vs the prev iter: 0.0005288787855473043\n",
      "kl div: 1.5645870964596118  |  iter: 1355  |  difference vs the prev iter: 0.0005441638611958233\n",
      "kl div: 1.5618014753518001  |  iter: 1360  |  difference vs the prev iter: 0.0005604143356736646\n",
      "kl div: 1.558930389581703  |  iter: 1365  |  difference vs the prev iter: 0.0005777226903838084\n",
      "kl div: 1.555968143642919  |  iter: 1370  |  difference vs the prev iter: 0.0005961909418039646\n",
      "kl div: 1.5529084911001794  |  iter: 1375  |  difference vs the prev iter: 0.0006159313548930179\n",
      "kl div: 1.5497445806362824  |  iter: 1380  |  difference vs the prev iter: 0.00063706711642042\n",
      "kl div: 1.546468899096422  |  iter: 1385  |  difference vs the prev iter: 0.0006597329144080177\n",
      "kl div: 1.5430732121481303  |  iter: 1390  |  difference vs the prev iter: 0.0006840753910748454\n",
      "kl div: 1.5395485035698624  |  iter: 1395  |  difference vs the prev iter: 0.0007102533658303045\n",
      "kl div: 1.535884914575432  |  iter: 1400  |  difference vs the prev iter: 0.0007384377619952254\n",
      "kl div: 1.5320716851535854  |  iter: 1405  |  difference vs the prev iter: 0.0007688111227406313\n",
      "kl div: 1.5280971000040136  |  iter: 1410  |  difference vs the prev iter: 0.0008015665686018636\n",
      "kl div: 1.5239484425097416  |  iter: 1415  |  difference vs the prev iter: 0.0008369060464494815\n",
      "kl div: 1.519611960991508  |  iter: 1420  |  difference vs the prev iter: 0.0008750376831727635\n",
      "kl div: 1.5150728525837438  |  iter: 1425  |  difference vs the prev iter: 0.000916172030080098\n",
      "kl div: 1.5103152711021512  |  iter: 1430  |  difference vs the prev iter: 0.0009605169987147999\n",
      "kl div: 1.505322366375222  |  iter: 1435  |  difference vs the prev iter: 0.00100827124448033\n",
      "kl div: 1.50007636353821  |  iter: 1440  |  difference vs the prev iter: 0.0010596158228650676\n",
      "kl div: 1.4945586915518916  |  iter: 1445  |  difference vs the prev iter: 0.00111470396334723\n",
      "kl div: 1.4887501705750876  |  iter: 1450  |  difference vs the prev iter: 0.0011736489118656657\n",
      "kl div: 1.4826312676173574  |  iter: 1455  |  difference vs the prev iter: 0.0012365099078130992\n",
      "kl div: 1.4761824286690528  |  iter: 1460  |  difference vs the prev iter: 0.001303276589504243\n",
      "kl div: 1.469384493269937  |  iter: 1465  |  difference vs the prev iter: 0.0013738523118216328\n",
      "kl div: 1.4622191937475733  |  iter: 1470  |  difference vs the prev iter: 0.0014480371912035661\n",
      "kl div: 1.4546697361020837  |  iter: 1475  |  difference vs the prev iter: 0.001525512005151386\n",
      "kl div: 1.4467214528150811  |  iter: 1480  |  difference vs the prev iter: 0.0016058243059835497\n",
      "kl div: 1.4383625097327744  |  iter: 1485  |  difference vs the prev iter: 0.001688378461297546\n",
      "kl div: 1.4295846404288182  |  iter: 1490  |  difference vs the prev iter: 0.0017724313637632605\n",
      "kl div: 1.4203838726392124  |  iter: 1495  |  difference vs the prev iter: 0.0018570955697245761\n",
      "kl div: 1.4107612037531612  |  iter: 1500  |  difference vs the prev iter: 0.0019413513196984145\n",
      "kl div: 1.4007231770641095  |  iter: 1505  |  difference vs the prev iter: 0.0020240683686096883\n",
      "kl div: 1.390282308934188  |  iter: 1510  |  difference vs the prev iter: 0.002104037801027525\n",
      "kl div: 1.3794573200900402  |  iter: 1515  |  difference vs the prev iter: 0.0021800129693960724\n",
      "kl div: 1.368273132855326  |  iter: 1520  |  difference vs the prev iter: 0.0022507576658543638\n",
      "kl div: 1.356760610088991  |  iter: 1525  |  difference vs the prev iter: 0.0023150984745636816\n",
      "kl div: 1.344956030363655  |  iter: 1530  |  difference vs the prev iter: 0.0023719774183543763\n",
      "kl div: 1.332900315882093  |  iter: 1535  |  difference vs the prev iter: 0.002420500376927537\n",
      "kl div: 1.3206380522482704  |  iter: 1540  |  difference vs the prev iter: 0.0024599767980588716\n",
      "kl div: 1.3082163595386744  |  iter: 1545  |  difference vs the prev iter: 0.0024899467694867727\n",
      "kl div: 1.2956836886625378  |  iter: 1550  |  difference vs the prev iter: 0.002510192829736857\n",
      "kl div: 1.283088623123482  |  iter: 1555  |  difference vs the prev iter: 0.0025207356578214046\n",
      "kl div: 1.270478762333486  |  iter: 1560  |  difference vs the prev iter: 0.0025218148720203004\n",
      "kl div: 1.2578997491245432  |  iter: 1565  |  difference vs the prev iter: 0.002513857958038157\n",
      "kl div: 1.2453944834165906  |  iter: 1570  |  difference vs the prev iter: 0.0024974417447529706\n",
      "kl div: 1.2330025401079208  |  iter: 1575  |  difference vs the prev iter: 0.002473251214055283\n",
      "kl div: 1.2207597866489273  |  iter: 1580  |  difference vs the prev iter: 0.002442040083466601\n",
      "kl div: 1.208698178148663  |  iter: 1585  |  difference vs the prev iter: 0.0024045964170109624\n",
      "kl div: 1.1968456973371167  |  iter: 1590  |  difference vs the prev iter: 0.0023617150609682724\n",
      "kl div: 1.1852264035923843  |  iter: 1595  |  difference vs the prev iter: 0.0023141772616317446\n",
      "kl div: 1.1738605579917767  |  iter: 1600  |  difference vs the prev iter: 0.002262736702160373\n",
      "kl div: 1.1627647977692699  |  iter: 1605  |  difference vs the prev iter: 0.0022081105618396712\n",
      "kl div: 1.1519523412334824  |  iter: 1610  |  difference vs the prev iter: 0.0021509740571747926\n",
      "kl div: 1.1414332112422867  |  iter: 1615  |  difference vs the prev iter: 0.002091957112932752\n",
      "kl div: 1.1312144706286593  |  iter: 1620  |  difference vs the prev iter: 0.0020316421589579026\n",
      "kl div: 1.121300466244659  |  iter: 1625  |  difference vs the prev iter: 0.001970562508709417\n",
      "kl div: 1.1116930797492057  |  iter: 1630  |  difference vs the prev iter: 0.0019092010764485412\n",
      "kl div: 1.1023919834399296  |  iter: 1635  |  difference vs the prev iter: 0.0018479894323604196\n",
      "kl div: 1.0933948989242854  |  iter: 1640  |  difference vs the prev iter: 0.001787307345399336\n",
      "kl div: 1.084697855749905  |  iter: 1645  |  difference vs the prev iter: 0.0017274829073530285\n",
      "kl div: 1.0762954465509345  |  iter: 1650  |  difference vs the prev iter: 0.0016687933814159006\n",
      "kl div: 1.0681810750444714  |  iter: 1655  |  difference vs the prev iter: 0.0016114667734190569\n",
      "kl div: 1.0603471933265798  |  iter: 1660  |  difference vs the prev iter: 0.0015556841154684697\n",
      "kl div: 1.052785525314823  |  iter: 1665  |  difference vs the prev iter: 0.001501582349259456\n",
      "kl div: 1.0454872737912864  |  iter: 1670  |  difference vs the prev iter: 0.0014492577001627982\n",
      "kl div: 1.0384433092336116  |  iter: 1675  |  difference vs the prev iter: 0.0013987693780783683\n",
      "kl div: 1.031644339316243  |  iter: 1680  |  difference vs the prev iter: 0.0013501434790508249\n",
      "kl div: 1.0250810586552335  |  iter: 1685  |  difference vs the prev iter: 0.0013033769413421936\n",
      "kl div: 1.018744278949032  |  iter: 1690  |  difference vs the prev iter: 0.0012584414534237975\n",
      "kl div: 1.0126250401132275  |  iter: 1695  |  difference vs the prev iter: 0.001215287224146433\n",
      "kl div: 1.006714703367044  |  iter: 1700  |  difference vs the prev iter: 0.0011738465489059546\n",
      "kl div: 1.0010050274455629  |  iter: 1705  |  difference vs the prev iter: 0.0011340371357069223\n",
      "kl div: 0.9954882292505625  |  iter: 1710  |  difference vs the prev iter: 0.001095765164106366\n",
      "kl div: 0.9901570302843287  |  iter: 1715  |  difference vs the prev iter: 0.0010589280719713878\n",
      "kl div: 0.9850046902282661  |  iter: 1720  |  difference vs the prev iter: 0.0010234170770565543\n",
      "kl div: 0.9800250289342707  |  iter: 1725  |  difference vs the prev iter: 0.000989119439511521\n",
      "kl div: 0.9752124380288836  |  iter: 1730  |  difference vs the prev iter: 0.0009559204988190961\n",
      "kl div: 0.9705618832171496  |  iter: 1735  |  difference vs the prev iter: 0.0009237054866424455\n",
      "kl div: 0.9660688982615236  |  iter: 1740  |  difference vs the prev iter: 0.0008923611585041069\n",
      "kl div: 0.9617295714950949  |  iter: 1745  |  difference vs the prev iter: 0.000861777253097662\n",
      "kl div: 0.9575405256387931  |  iter: 1750  |  difference vs the prev iter: 0.0008318478014425201\n",
      "kl div: 0.9534988915852952  |  iter: 1755  |  difference vs the prev iter: 0.0008024723088981833\n",
      "kl div: 0.9496022767561193  |  iter: 1760  |  difference vs the prev iter: 0.0007735568183147024\n",
      "kl div: 0.9458487285809495  |  iter: 1765  |  difference vs the prev iter: 0.0007450148627775599\n",
      "kl div: 0.9422366935959791  |  iter: 1770  |  difference vs the prev iter: 0.0007167683231221744\n",
      "kl div: 0.9387649726763853  |  iter: 1775  |  difference vs the prev iter: 0.0006887481799208173\n",
      "kl div: 0.9354326728842921  |  iter: 1780  |  difference vs the prev iter: 0.000660895171345377\n",
      "kl div: 0.9322391564645489  |  iter: 1785  |  difference vs the prev iter: 0.00063316034328742\n",
      "kl div: 0.929183987529366  |  iter: 1790  |  difference vs the prev iter: 0.0006055054870731658\n",
      "kl div: 0.9262668770331319  |  iter: 1795  |  difference vs the prev iter: 0.0005779034577916287\n",
      "kl div: 0.9234876266837322  |  iter: 1800  |  difference vs the prev iter: 0.000550338360433722\n",
      "kl div: 0.9208460724930252  |  iter: 1805  |  difference vs the prev iter: 0.0005228055904841211\n",
      "kl div: 0.9183420287228037  |  iter: 1810  |  difference vs the prev iter: 0.0004953117288034603\n",
      "kl div: 0.9159752330146697  |  iter: 1815  |  difference vs the prev iter: 0.000467874267774393\n",
      "kl div: 0.9137452935580196  |  iter: 1820  |  difference vs the prev iter: 0.00044052117290693804\n",
      "kl div: 0.9116516391280678  |  iter: 1825  |  difference vs the prev iter: 0.00041329027258973916\n",
      "kl div: 0.9096934728426012  |  iter: 1830  |  difference vs the prev iter: 0.0003862284800194571\n",
      "kl div: 0.9078697304743699  |  iter: 1835  |  difference vs the prev iter: 0.00035939085490555023\n",
      "kl div: 0.9061790440620953  |  iter: 1840  |  difference vs the prev iter: 0.0003328395073070034\n",
      "kl div: 0.9046197115273332  |  iter: 1845  |  difference vs the prev iter: 0.00030664237629396407\n",
      "kl div: 0.9031896728713702  |  iter: 1850  |  difference vs the prev iter: 0.00028087188689107645\n",
      "kl div: 0.9018864934045207  |  iter: 1855  |  difference vs the prev iter: 0.0002556035340675056\n",
      "kl div: 0.9007073543094647  |  iter: 1860  |  difference vs the prev iter: 0.00023091440069833435\n",
      "kl div: 0.8996490506786565  |  iter: 1865  |  difference vs the prev iter: 0.00020688166423254994\n",
      "kl div: 0.8987079969815149  |  iter: 1870  |  difference vs the prev iter: 0.00018358111284388912\n",
      "kl div: 0.8978802397495126  |  iter: 1875  |  difference vs the prev iter: 0.00016108571342210443\n",
      "kl div: 0.8971614770864496  |  iter: 1880  |  difference vs the prev iter: 0.0001394642650738298\n",
      "kl div: 0.8965470844447475  |  iter: 1885  |  difference vs the prev iter: 0.00011878017256949924\n"
     ]
    }
   ],
   "source": [
    "predicted_mean, predicted_variance, predicted_weights, plot = traditional_EM()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- TARGET DISTRIBUTION ------\n",
      "component mean: 3.753669186817536 | variance: 1.4033099447563646 | weight: 0.07712134160131523\n",
      "component mean: 8.354014774500548 | variance: 1.4085399998986485 | weight: 0.05884515529781231\n",
      "component mean: -5.430458731909366 | variance: 0.7609471056871673 | weight: 0.07088369522100216\n",
      "component mean: -9.405707844197863 | variance: 0.8195044497661425 | weight: 0.07051182748326187\n",
      "component mean: 3.8303009698309616 | variance: 1.4948393230544235 | weight: 0.06274113437319175\n",
      "component mean: -5.13589832969503 | variance: 1.4535721118491596 | weight: 0.06418274170737653\n",
      "component mean: -3.9572820505726405 | variance: 0.8438852291476824 | weight: 0.06987047417552879\n",
      "component mean: -10.418608773737912 | variance: 1.4796950818866659 | weight: 0.06975642466722631\n",
      "component mean: -1.5542419190164782 | variance: 0.7745868345096016 | weight: 0.0661071110833318\n",
      "component mean: 5.180346995409693 | variance: 1.0911518801538571 | weight: 0.06728669524826118\n",
      "component mean: 3.9981356840320714 | variance: 1.2042818078970157 | weight: 0.06389428015224007\n",
      "component mean: -10.839579420636483 | variance: 0.8669596778301731 | weight: 0.06946473969367514\n",
      "component mean: 2.5477324894545674 | variance: 0.8929058392457853 | weight: 0.06064071620469778\n",
      "component mean: -7.881256939249834 | variance: 1.3358604966484506 | weight: 0.0634434314448284\n",
      "component mean: -9.63360715699235 | variance: 1.4953931064240518 | weight: 0.06525023164625049\n",
      "----- LEARNED DISTRIBUTION ------\n",
      "component mean: -8.753133504099774 | variance: 0.618122438543246 | weight: 0.046595571644937155\n",
      "component mean: -5.32812599290347 | variance: 0.5209298612802223 | weight: 0.07423761527599984\n",
      "component mean: -1.8045658587681666 | variance: 0.6347007810407316 | weight: 0.039578514533697276\n",
      "component mean: -3.6771293221516586 | variance: 1.1140337311795088 | weight: 0.004343303424840072\n",
      "component mean: -10.297891512556149 | variance: 1.2734852515915367 | weight: 0.23384628816369307\n",
      "component mean: 3.7550982871320207 | variance: 1.5851246864409887 | weight: 0.12432625598759468\n",
      "component mean: 4.822090810543632 | variance: 1.195946427863488 | weight: 0.09401236506165164\n",
      "component mean: 2.9198453885820848 | variance: 1.145978635728773 | weight: 0.08794971296147645\n",
      "component mean: 8.39482290372017 | variance: 1.3808780298278156 | weight: 0.058571047396536645\n",
      "component mean: 3.85603639465189 | variance: 1.6299938274087216 | weight: 0.015369731694565639\n",
      "component mean: -3.9642791770743253 | variance: 0.4137559939711065 | weight: 0.034757772081491556\n",
      "component mean: -3.8145908538707634 | variance: 1.3308570492382976 | weight: 0.049003619011369084\n",
      "component mean: -1.0627494323294036 | variance: 0.6543957747382289 | weight: 0.02161290474042867\n",
      "component mean: -6.94064042736814 | variance: 2.697629272721288 | weight: 0.10305945494763101\n",
      "component mean: 5.126019145682295 | variance: 2.4219478177941323 | weight: 0.012735843074087191\n"
     ]
    }
   ],
   "source": [
    "print(\"----- TARGET DISTRIBUTION ------\")\n",
    "for i in range(k):\n",
    "    print(\"component mean:\", mean[i], \"| variance:\", variance[i], \"| weight:\", weights[i])\n",
    "\n",
    "print(\"----- LEARNED DISTRIBUTION ------\")\n",
    "for i in range(k):\n",
    "    print(\"component mean:\", predicted_mean[i], \"| variance:\", predicted_variance[i], \"| weight:\", predicted_weights[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([i for i in range(len(plot))], plot)\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"kl_divergence\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "learned_mixture_index = np.random.choice(k, size = n, replace = True, p = predicted_weights)\n",
    "learned_data = np.fromiter((np.random.normal(loc = predicted_mean[index], scale = np.sqrt([predicted_variance[index]])[0]) for index in learned_mixture_index), float)\n",
    "assert data.shape == (n, )\n",
    "\n",
    "plt.hist(learned_data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Learned distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data, bins=\"auto\", density=True)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"f(x)\")\n",
    "plt.title(\"Actual distribution\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e145918ee62325bb783ae69933f229276b5458d89ab4d949d12da7376064d41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
